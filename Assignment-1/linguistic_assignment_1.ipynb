{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHnbyVzqiftH"
      },
      "source": [
        "# **Data Loading**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTpJ73NvVhuM",
        "outputId": "3239fd72-cdce-470b-da76-853c7cac83c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_1008\\2162734918.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  data = pd.read_csv(\"gu_100.txt\",on_bad_lines='skip', sep='delimiter',header = None, encoding = 'utf-8')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                   0\n",
            "0  ૯મી ઓગસ્ટ ૨૦૧૬ના રોજ આદિવાસી વિકાસ સંગઠન દ્વાર...\n",
            "1  આ પતાવટની આંતરમાળખા ખૂબ સારી રીતે વિકસિત નથી, ...\n",
            "2  વહીવટ બિલ્ડિંગ નજીક પાછળના બાજુ પર, હોટેલ આંતર...\n",
            "3  ગુરુવારે સવારે બેંકો ખુલતા પહેલા પ્રતિબંધિત નો...\n",
            "4  ઈન્ડિયન આઈડલ 11ના આગામી એપિસોડમાં ઉદિત નારાયણ ...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv(\"gu_100.txt\",on_bad_lines='skip', sep='delimiter',header = None, encoding = 'utf-8')\n",
        "#importing dataframe\n",
        "\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI3WyiJQikX4"
      },
      "source": [
        "**https://learngujaratiwithme.com/gujarati-vowels/ getting list from this website**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3frmWd6GHgN"
      },
      "outputs": [],
      "source": [
        "swar = ['અ', 'આ', 'ઇ', 'ઈ', 'ઉ', 'ઊ', 'ઋ', 'ઌ', 'ઍ', 'એ', 'ઐ', 'ઑ', 'ઓ', 'ઔ','અં','અઃ']\n",
        "matra = ['ા', 'િ', 'ી', 'ુ', 'ૂ', 'ૃ', 'ૄ', 'ૅ', 'ે', 'ૈ', 'ૉ', 'ો', 'ૌ','ં','ઃ']\n",
        "vyanjan = ['ક', 'ખ', 'ગ', 'ઘ', 'ઙ', 'ચ', 'છ', 'જ', 'ઝ', 'ઞ', 'ટ', 'ઠ', 'ડ', 'ઢ', 'ણ', 'ત', 'થ', 'દ', 'ધ', 'ન', 'પ', 'ફ', 'બ', 'ભ', 'મ', 'ય', 'ર', 'લ', 'ળ', 'વ', 'શ', 'ષ', 'સ', 'હ']\n",
        "gujarati_dict = {\n",
        "    'ા': 'આ',\n",
        "    'િ': 'ઇ',\n",
        "    'ી': 'ઈ',\n",
        "    'ુ': 'ઉ',\n",
        "    'ૂ': 'ઊ',\n",
        "    'ૃ': 'ઋ',\n",
        "    'ૄ': 'ઌ',\n",
        "    'ૅ': 'ઍ',\n",
        "    'ે': 'એ',\n",
        "    'ૈ': 'ઐ',\n",
        "    'ૉ': 'ઑ',\n",
        "    'ો': 'ઓ',\n",
        "    'ૌ': 'ઔ',\n",
        "    'ં':  'અં',\n",
        "    'ઃ':  'અઃ'\n",
        "}\n",
        "\n",
        "word = \"માત્ર\"\n",
        "punctuation_list = [\n",
        " 'a','b','c','d','e','f','g','h','i','j',\n",
        " 'k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','0','1','2','3','4','5','6','7','8','9',\n",
        " 'A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z',\n",
        " '!','\"','\\\\','#','\\\\','$','%','\\\\','&',\"'\",'\\\\','(','\\\\',')','\\\\','*','\\\\','+',',','\\\\','-','\\\\','.','/',\n",
        " ':',';','<','=','>','\\\\','?','@','\\\\','[','\\\\','\\\\','\\\\',']','\\\\','^','_','`','\\\\','{','\\\\','|','\\\\','}','\\\\','~']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmb1OXL9ivTq"
      },
      "source": [
        "# **Q1 Perform the Unicode correction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV2n191t_8xk",
        "outputId": "6fa98e20-1972-46cc-88b2-9039cc6d6f67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['સ', 'ં', 'ગ', 'ઠ', 'ન']\n"
          ]
        }
      ],
      "source": [
        "print(list('સંગઠન'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omgqajwTjEgw"
      },
      "source": [
        "**wrote function for unicode correction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpZUtdm5-R8H"
      },
      "outputs": [],
      "source": [
        "\n",
        "def correct_unicode(word):\n",
        "  correct_word=\"\"\n",
        "  length = len(word)\n",
        "  for i in range(length):\n",
        "\n",
        "        if word[i] in vyanjan:\n",
        "          correct_word +=' '+word[i]+\"્\"\n",
        "          if i<=length-2 and (word[i+1]=='्' or word[i+1] in punctuation_list):\n",
        "            pass\n",
        "          elif i<=length-2 and word[i+1] in matra:\n",
        "            correct_word +=' ' +gujarati_dict[word[i+1]]\n",
        "          elif i<=length-2 and (word[i+1] in vyanjan or word[i+1] in swar) :\n",
        "            correct_word +=' ' +'અ'\n",
        "          elif i == length - 1:\n",
        "                correct_word +=' ' +'અ'\n",
        "        elif word[i] in swar :\n",
        "          correct_word +=' ' +word[i]\n",
        "\n",
        "\n",
        "  return correct_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75zwGwAlBLW7",
        "outputId": "26212862-bd2d-4061-897f-62f96ad5a6f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ન્ ઇ જ્ અ\n"
          ]
        }
      ],
      "source": [
        "print(correct_unicode('નિજ'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlsBPfyjju5K"
      },
      "source": [
        "**print for first 10 row from data file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2s8bd2-SR9Pw"
      },
      "outputs": [],
      "source": [
        "counter = 0\n",
        "processed_words = [] # list contain all the corrected unicode\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "    # Check if we have processed 10 rows\n",
        "    # if counter >= 10 :\n",
        "        # break\n",
        "\n",
        "    # Get the text data from the current row\n",
        "    text = row[0]\n",
        "\n",
        "    # Split the text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Process each word and store cleaned versions\n",
        "    for word in words:\n",
        "        cleaned_word = correct_unicode(word)  # Explain what this function does\n",
        "        processed_words.append(cleaned_word)\n",
        "        # print(f\"{word} => {cleaned_word}\")\n",
        "\n",
        "    # Increment the counter\n",
        "    # counter += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BJeaf6peCYO",
        "outputId": "f8fb6d14-91be-4541-ba6e-9ac6394d7c2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[' મ્ ઈ', ' ઓ ગ્ અ સ્ ટ્ અ', ' ન્ આ', ' ર્ ઓ જ્ અ', ' આ દ્ ઇ વ્ આ સ્ ઈ', ' વ્ ઇ ક્ આ સ્ અ', ' સ્ અં ગ્ અ ઠ્ અ ન્ અ', ' દ્ વ્ આ ર્ આ', ' આ દ્ ઇ વ્ આ સ્ ઈ', ' ભ્ અ વ્ અ ન્ અ', ' ખ્ આ ત્ એ', ' ખ્ ઊ બ્ અ', ' જ્ અ', ' ઉ ત્ સ્ આ હ્ અ ભ્ એ ર્ અ', ' ઉ જ્ અ વ્ અ ણ્ ઈ', ' ક્ અ ર્ અ વ્ આ મ્ આ', ' આ વ્ અ શ્ એ', ' આ', ' પ્ અ ત્ આ વ્ અ ટ્ અ ન્ ઈ', ' આ ત્ અ ર્ અ મ્ આ ળ્ અ ખ્ આ', ' ખ્ ઊ બ્ અ', ' સ્ આ ર્ ઈ', ' ર્ ઈ ત્ એ', ' વ્ ઇ ક્ અ સ્ ઇ ત્ અ', ' ન્ અ થ્ ઈ', ' પ્ અ ર્ અં ત્ ઉ', ' પ્ ર્ અ વ્ આ સ્ ઈ ઓ', ' અ ન્ એ', ' ઉ દ્ ય્ ઓ ગ્ અ પ્ અ ત્ ઇ ઓ ન્ ઈ', ' ડ્ અ ઝ્ અ ન્ એ ક્ અ', ' અ હ્ ઈ', ' બ્ અ ધ્ આ', ' જ્ અ', ' આ વ્ એ', ' છ્ એ', ' વ્ અ હ્ ઈ વ્ અ ટ્ અ', ' બ્ ઇ લ્ ડ્ ઇ ગ્ અ', ' ન્ અ જ્ ઈ ક્ અ', ' પ્ આ છ્ અ ળ્ અ ન્ આ', ' બ્ આ જ્ ઉ', ' પ્ અ ર્', ' હ્ ઓ ટ્ એ લ્ અ', ' આ ત્ અ ર્ ઇ ક્ અ', ' વ્ ઇ સ્ ત્ આ ર્', ' ત્ એ ન્ આ', ' અ ત્ અ', ' બ્ એ', ' થ્ ઈ', ' ચ્ આ ર્ અ', ' મ્ આ ળ્ અ ન્ ઉ', ' ર્ અ હ્ એ ણ્ આ ક્ અ', ' ઇ મ્ આ ર્ અ ત્ ઓ', ' અ ડ્ ઈ ન્ એ', ' મ્ અ ર્ ય્ આ દ્ ઇ ત્ અ', ' ક્ અ ર્ એ', ' છ્ એ', ' ગ્ ઉ ર્ ઉ વ્ આ ર્ એ', ' સ્ અ વ્ આ ર્ એ', ' બ્ એ ક્ ઓ', ' ખ્ ઉ લ્ અ ત્ આ', ' પ્ અ હ્ એ લ્ આ', ' પ્ ર્ અ ત્ ઇ બ્ અં ધ્ ઇ ત્ અ', ' ન્ ઓ ટ્ ઓ', ' લ્ અ ઇ ન્ એ', ' મ્ ઓ ટ્ ઈ', ' સ્ અં ખ્ ય્ આ મ્ આ', ' લ્ ઓ ક્ ઓ', ' બ્ એ ક્ ઓ ન્ ઈ', ' બ્ અ હ્ આ ર્ અ', ' ઊ ભ્ આ', ' ર્ અ હ્ ઈ', ' ગ્ અ ય્ આ', ' હ્ અ ત્ આ', ' ઈ ન્ ડ્ ઇ ય્ અ ન્ અ', ' આ ઈ ડ્ અ લ્ અ', ' ન્ આ', ' આ ગ્ આ મ્ ઈ', ' એ પ્ ઇ સ્ ઓ ડ્ અ મ્ આ', ' ઉ દ્ ઇ ત્ અ', ' ન્ આ ર્ આ ય્ અ ણ્ અ', ' અ ન્ એ', ' અ લ્ અ ક્ આ', ' ય્ આ જ્ ઞ્ ઇ ક્ અ', ' મ્ અ હ્ એ મ્ આ ન્ અ', ' બ્ અ ન્ અ શ્ એ', ' ત્ એ', ' બ્ આ જ્ ઉ ન્ ઈ', ' મ્ એ ન્ સ્ ઇ સ્ સ્ અ', ' સ્ આ થ્ એ', ' ત્ અ મ્ આ ર્ આ', ' ઘ્ ઊ ટ્ અ ણ્ અ ન્ ઈ', ' સ્ અં ય્ ઉ ક્ ત્ અ', ' દ્ વ્ આ ર્ આ', ' શ્ ઓ ક્ અ', ' શ્ ઓ ષ્ અ ણ્ અ', ' મ્ આ ટ્ એ', ' જ્ અ વ્ આ બ્ અ દ્ આ ર્ અ', ' છ્ એ', ' દ્ એ શ્ અ ન્ ઈ', ' ઉ ચ્ ચ્ અ']\n"
          ]
        }
      ],
      "source": [
        "N = 100\n",
        "result=[]\n",
        "result = processed_words[:N]\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2GKqR6hWAmo"
      },
      "source": [
        "# **Q2 Find all characters and syllables. Store a list of them in descending order of their frequencies**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM6wpghIhq4T"
      },
      "source": [
        "# **uni-gram and bi-gram frequencies of Character**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fR6WzHfoTlQe"
      },
      "outputs": [],
      "source": [
        "# craeted global list to store frequency for character\n",
        "unigram_char_list=[]\n",
        "\n",
        "unigram_char_list_sorted=[]\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def unigram_for_char(each_word, vyanjan_list,unigram_char_list):\n",
        "  # Join the strings and remove spaces\n",
        "  joined_string = ''.join(each_word).replace(\" \", \"\")\n",
        "  # print(joined_string)\n",
        "  # Count character frequencies, treating '્' as part of the preceding character\n",
        "  char_counts = Counter(\n",
        "      c for c in joined_string if c != \"્\" or c == joined_string[joined_string.index(c) - 1]\n",
        "  )\n",
        "\n",
        "  # Sort characters by frequency (descending)\n",
        "  sorted_chars = sorted(char_counts, key=char_counts.get, reverse=True)\n",
        "\n",
        "  # Create a list of characters with halant (if needed)\n",
        "  # char_freq_list = [\n",
        "  #     (char + \"્\" if char in vyanjan_list else char, char_counts[char])\n",
        "  #     for char in sorted_chars\n",
        "  # ]\n",
        "\n",
        "  for char, freq in char_counts.items():\n",
        "        char_key = char + \"્\" if char in vyanjan_list else char\n",
        "        found = False\n",
        "        for i, (existing_char, existing_freq) in enumerate(unigram_char_list):\n",
        "            if existing_char == char_key:\n",
        "                unigram_char_list[i] = (existing_char, existing_freq + freq)\n",
        "                found = True\n",
        "                break\n",
        "        if not found:\n",
        "            unigram_char_list.append((char_key, freq))\n",
        "\n",
        "def sort_list_by_frequency(char_freq_list):\n",
        "    return sorted(char_freq_list, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaFV1bNSeHmc",
        "outputId": "0cff4847-f1b3-412e-b0ac-debc83c34c4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ', 6990268), ('આ', 3692279), ('એ', 2522856), ('ર્', 2128526), ('ન્', 1734112), ('ઈ', 1589073), ('ક્', 1386555), ('મ્', 1324843), ('ઓ', 1236360), ('ત્', 1207724), ('વ્', 1149790), ('સ્', 976491), ('પ્', 867048), ('ઇ', 838885), ('ય્', 745130), ('લ્', 684911), ('ઉ', 673954), ('જ્', 585042), ('ટ્', 520557), ('હ્', 516880)]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for word in processed_words:\n",
        "\n",
        "  unigram_for_char(word, vyanjan,unigram_char_list) # unigram for character\n",
        "\n",
        "  # print(\" unigram characters \")\n",
        "\n",
        "unigram_char_list_sorted=sort_list_by_frequency(unigram_char_list)\n",
        "\n",
        "print(unigram_char_list_sorted[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbxJT60oittx",
        "outputId": "6b44763b-b45d-4b92-c5b5-9b4e412fa321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ', 6990268), ('આ', 3692279), ('એ', 2522856), ('ર્', 2128526), ('ન્', 1734112), ('ઈ', 1589073), ('ક્', 1386555), ('મ્', 1324843), ('ઓ', 1236360), ('ત્', 1207724), ('વ્', 1149790), ('સ્', 976491), ('પ્', 867048), ('ઇ', 838885), ('ય્', 745130), ('લ્', 684911), ('ઉ', 673954), ('જ્', 585042), ('ટ્', 520557), ('હ્', 516880)]\n"
          ]
        }
      ],
      "source": [
        "print(unigram_char_list_sorted[:20])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSzwspIav4wP"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeRE5MPxlzS-"
      },
      "outputs": [],
      "source": [
        "bigram_char_list=[]\n",
        "bigram_char_list_sorted=[]\n",
        "def sort_list_by_frequency(char_freq_list):\n",
        "    return sorted(char_freq_list, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "def bigram_for_char(each_word, vyanjan_list,bigram_char_list):\n",
        "\n",
        "    bigram_counts = {}\n",
        "    joined_string = ''.join(each_word).replace(\" \", \"\")\n",
        "\n",
        "    for i in range(len(joined_string) - 1):\n",
        "        char1 = joined_string[i]\n",
        "        char2 = joined_string[i + 1]\n",
        "\n",
        "        if char1 == \"્\":\n",
        "            continue\n",
        "\n",
        "        elif char2 == \"્\":\n",
        "            if i + 2 < len(joined_string) and joined_string[i + 2] != \"્\":\n",
        "                bigram = char1 + joined_string[i + 1] + joined_string[i + 2]\n",
        "                i += 1\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "        else:\n",
        "            bigram = char1 + char2\n",
        "\n",
        "        bigram_counts[bigram] = bigram_counts.get(bigram, 0) + 1\n",
        "\n",
        "\n",
        "    bigram_list = [(bigram, count) for bigram, count in bigram_counts.items()]\n",
        "\n",
        "\n",
        "    for bigram, count in bigram_list:\n",
        "        found = False\n",
        "        for i, (existing_bigram, existing_count) in enumerate(bigram_char_list):\n",
        "            if existing_bigram == bigram:\n",
        "                bigram_char_list[i] = (existing_bigram, existing_count + count)\n",
        "                found = True\n",
        "                break\n",
        "        if not found:\n",
        "            bigram_char_list.append((bigram, count))\n",
        "\n",
        "    bigram_list = [(bigram, count) for bigram, count in bigram_counts.items()]\n",
        "    # bigram_list.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return bigram_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wimm_xpUn5Du",
        "outputId": "3df5d258-a8b3-4e14-c56d-7251b24aec2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર્અ', 933782), ('અર', 856288), ('અન', 740690), ('ક્અ', 628714), ('મ્આ', 578634), ('આર', 436837), ('પ્અ', 419131), ('મ્અ', 410518), ('અમ', 405502), ('સ્અ', 404345), ('વ્આ', 403416), ('ન્અ', 383007), ('ન્એ', 374190), ('અત', 357387), ('અવ', 352507), ('ત્અ', 347304), ('ન્આ', 338880), ('છ્એ', 322605), ('વ્અ', 322164), ('ય્અ', 280834)]\n"
          ]
        }
      ],
      "source": [
        "for word in processed_words:\n",
        "   bigram_for_char(word, vyanjan,bigram_char_list) # bigram for character\n",
        "bigram_char_list_sorted=sort_list_by_frequency(bigram_char_list)\n",
        "print(bigram_char_list_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWaHqZpM3JuI"
      },
      "source": [
        "# **uni-gram and bi-gram frequencies of syllables**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfSnc31S3Zbs"
      },
      "outputs": [],
      "source": [
        "unigram_syllables_list=[]\n",
        "unigram_syllabless=[]\n",
        "unigram_syllables_list_sorted=[]\n",
        "### unigram syllables ####################################################################################################################\n",
        "def remove_last_two(string):\n",
        "\n",
        "  if not string:\n",
        "    return \"\"\n",
        "  return string[:-1]\n",
        "def unigram_syllables(text,swar,vyanjan,swapped_dict,unigram_syllables_list,unigram_syllabless):\n",
        "\n",
        "    i = 0\n",
        "    syllables_counts = {}\n",
        "    text = ''.join(text).replace(\" \", \"\")\n",
        "    syllable=[]\n",
        "    while i < len(text):\n",
        "          ch=\"\"\n",
        "          while i < len(text) and text[i] not in swar:\n",
        "\n",
        "              ch += text[i]\n",
        "\n",
        "              i+=1\n",
        "          if i < len(text) and len(ch)>1 and text[i] == 'અ':\n",
        "\n",
        "            ch=remove_last_two(ch)\n",
        "          elif i < len(text) and len(ch)>1 :\n",
        "            ch=remove_last_two(ch)\n",
        "            ch+=swapped_dict[text[i]]\n",
        "          elif i < len(text) :\n",
        "            ch = ch+text[i]\n",
        "          syllables_counts[ch] = syllables_counts.get(ch, 0) + 1\n",
        "          syllable.append(ch)\n",
        "          i+=1\n",
        "\n",
        "    syllable_list = [(syllable, count) for syllable, count in syllables_counts.items()]\n",
        "\n",
        "    syllable_list.sort(key=lambda x: x[1], reverse=True)\n",
        "    for syllable, count in syllable_list:\n",
        "        found = False\n",
        "        for i, (existing_syllable, existing_count) in enumerate(unigram_syllables_list):\n",
        "            if existing_syllable == syllable:\n",
        "                unigram_syllables_list[i] = (existing_syllable, existing_count + count)\n",
        "                unigram_syllabless.append(existing_syllable)\n",
        "                found = True\n",
        "                break\n",
        "        if not found:\n",
        "            unigram_syllables_list.append((syllable, count))\n",
        "            unigram_syllabless.append(syllable)\n",
        "\n",
        "    # print(\" unigram syllables \")\n",
        "    # print( syllable_list)\n",
        "    # return syllable\n",
        "\n",
        "\n",
        "# Example usage\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeWdjw4_ti-k",
        "outputId": "932c764f-95e2-4b29-b4ec-3e8c9bfe16df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર', 769936), ('ક', 604335), ('મા', 567925), ('પ', 392100), ('મ', 383918), ('વા', 370332), ('ન', 369827), ('ને', 366840), ('અ', 353767), ('સ', 349703), ('ના', 334899), ('આ', 330561), ('છે', 322018), ('ત', 306720), ('વ', 286878), ('એ', 250054), ('ની', 240032), ('જ', 222568), ('લ', 215566), ('તે', 213475), ('રી', 208623), ('હ', 189752), ('કા', 188375), ('રા', 185782), ('ય', 180878), ('ગ', 178879), ('કે', 174127), ('તા', 165196), ('બ', 159918), ('શ', 150628), ('દ', 146208), ('ણ', 146069), ('સા', 146033), ('ટ', 141382), ('ઓ', 135868), ('થી', 133064), ('લા', 128953), ('રે', 127510), ('ઈ', 120587), ('કો', 116367)]\n",
            "['મી', '@', 'ઓ', 'ગ', 'સ્ટ', '@', 'ના', '@', 'રો', 'જ', '@', 'આ', 'દિ', 'વા', 'સી', '@', 'વિ', 'કા', 'સ', '@']\n"
          ]
        }
      ],
      "source": [
        "swapped_dict = {v: k for k, v in gujarati_dict.items()}\n",
        "spchar = '@'\n",
        "count =0\n",
        "for word in processed_words:\n",
        "\n",
        "  unigram_syllables(word,swar,vyanjan,swapped_dict,unigram_syllables_list,unigram_syllabless)\n",
        "  unigram_syllabless.append(spchar)\n",
        "\n",
        "\n",
        "\n",
        "unigram_syllables_list_sorted=sort_list_by_frequency(unigram_syllables_list)\n",
        "# print(unigram_syllabless)\n",
        "print(unigram_syllables_list_sorted[:40])\n",
        "# print(unigram_syllables_list[:20])\n",
        "print(unigram_syllabless[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMSicu5R8Fcc"
      },
      "outputs": [],
      "source": [
        "bigram_syllables_list=[]\n",
        "bigram_syllables_list_sorted=[]\n",
        "def get_bisyllable_frequency(list_of_syllables,bigram_syllables_list):\n",
        "    biagram_syllables_list = []\n",
        "    for i in range(len(list_of_syllables) - 1):\n",
        "        if list_of_syllables[i+1] == \"@\":\n",
        "            pass\n",
        "        elif list_of_syllables[i] != \"@\":\n",
        "            pair = list_of_syllables[i] + \" \" + list_of_syllables[i+1]\n",
        "            biagram_syllables_list.append(pair)\n",
        "\n",
        "    bisyllable_frequency = {}\n",
        "    i = 0\n",
        "    while i < len(biagram_syllables_list):\n",
        "        ch = biagram_syllables_list[i]\n",
        "        bisyllable_frequency[ch] = bisyllable_frequency.get(ch, 0) + 1\n",
        "        i += 1\n",
        "\n",
        "    sort_bisyllable_list = [(bisyllable, count) for bisyllable, count in bisyllable_frequency.items()]\n",
        "    sort_bisyllable_list.sort(key=lambda x: x[1], reverse=True)\n",
        "    return sort_bisyllable_list\n",
        "\n",
        "# print(bigram_syllables_list_sorted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTIMGoeSjie6",
        "outputId": "8bcc77d1-4865-4b99-b6e7-3d27438ab11d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ ને', 156342), ('ક ર', 95414), ('પ ર', 84047), ('મા ટે', 83961), ('ર વા', 69732), ('એ ક', 68081), ('પ ણ', 58282), ('ક રી', 56269), ('વા મા', 55647), ('સા થે', 45581), ('તે મ', 42669), ('ત મા', 40013), ('કા ર', 38255), ('સ મ', 33365), ('હ તી', 32939), ('ન થી', 32320), ('ઉ પ', 29503), ('આ વે', 28206), ('ત મે', 26162), ('વ વા', 24444)]\n"
          ]
        }
      ],
      "source": [
        "bigram_syllables_list_sorted=get_bisyllable_frequency(unigram_syllabless,bigram_syllables_list)\n",
        "print(bigram_syllables_list_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoodWj3oFbB5"
      },
      "source": [
        "# **Q4 install dependency**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAzFzPflFuuR",
        "outputId": "f9a59d17-9f46-48ca-d5a5-4f4baf6dcd9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "  Obtaining dependency information for sentencepiece from https://files.pythonhosted.org/packages/cc/07/d6951e3b4079df819d76353302fc3e76835252e7e0b6366f96a03d87ea5f/sentencepiece-0.1.99-cp311-cp311-win_amd64.whl.metadata\n",
            "  Downloading sentencepiece-0.1.99-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
            "Downloading sentencepiece-0.1.99-cp311-cp311-win_amd64.whl (977 kB)\n",
            "   ---------------------------------------- 0.0/977.5 kB ? eta -:--:--\n",
            "   ---------------------------------------- 10.2/977.5 kB ? eta -:--:--\n",
            "    -------------------------------------- 20.5/977.5 kB 330.3 kB/s eta 0:00:03\n",
            "   - ------------------------------------- 30.7/977.5 kB 217.9 kB/s eta 0:00:05\n",
            "   --- ----------------------------------- 81.9/977.5 kB 508.4 kB/s eta 0:00:02\n",
            "   --- ----------------------------------- 92.2/977.5 kB 525.1 kB/s eta 0:00:02\n",
            "   ---- --------------------------------- 112.6/977.5 kB 504.4 kB/s eta 0:00:02\n",
            "   ------ ------------------------------- 163.8/977.5 kB 614.4 kB/s eta 0:00:02\n",
            "   ------ ------------------------------- 174.1/977.5 kB 551.6 kB/s eta 0:00:02\n",
            "   ------ ------------------------------- 174.1/977.5 kB 551.6 kB/s eta 0:00:02\n",
            "   -------- ----------------------------- 215.0/977.5 kB 504.4 kB/s eta 0:00:02\n",
            "   --------- ---------------------------- 245.8/977.5 kB 502.2 kB/s eta 0:00:02\n",
            "   --------- ---------------------------- 256.0/977.5 kB 491.5 kB/s eta 0:00:02\n",
            "   ----------- -------------------------- 297.0/977.5 kB 509.3 kB/s eta 0:00:02\n",
            "   ------------ ------------------------- 327.7/977.5 kB 507.9 kB/s eta 0:00:02\n",
            "   ------------- ------------------------ 337.9/977.5 kB 487.6 kB/s eta 0:00:02\n",
            "   ------------- ------------------------ 358.4/977.5 kB 495.2 kB/s eta 0:00:02\n",
            "   --------------- ---------------------- 389.1/977.5 kB 494.6 kB/s eta 0:00:02\n",
            "   --------------- ---------------------- 409.6/977.5 kB 501.1 kB/s eta 0:00:02\n",
            "   ---------------- --------------------- 419.8/977.5 kB 485.3 kB/s eta 0:00:02\n",
            "   ----------------- -------------------- 440.3/977.5 kB 482.7 kB/s eta 0:00:02\n",
            "   ----------------- -------------------- 460.8/977.5 kB 480.3 kB/s eta 0:00:02\n",
            "   ------------------ ------------------- 471.0/977.5 kB 468.3 kB/s eta 0:00:02\n",
            "   ------------------ ------------------- 471.0/977.5 kB 468.3 kB/s eta 0:00:02\n",
            "   ------------------- ------------------ 501.8/977.5 kB 449.3 kB/s eta 0:00:02\n",
            "   -------------------- ----------------- 522.2/977.5 kB 455.1 kB/s eta 0:00:02\n",
            "   --------------------- ---------------- 542.7/977.5 kB 448.2 kB/s eta 0:00:01\n",
            "   --------------------- ---------------- 542.7/977.5 kB 448.2 kB/s eta 0:00:01\n",
            "   --------------------- ---------------- 553.0/977.5 kB 428.7 kB/s eta 0:00:01\n",
            "   ---------------------- --------------- 573.4/977.5 kB 428.9 kB/s eta 0:00:01\n",
            "   ---------------------- --------------- 583.7/977.5 kB 417.0 kB/s eta 0:00:01\n",
            "   ----------------------- -------------- 604.2/977.5 kB 413.0 kB/s eta 0:00:01\n",
            "   ----------------------- -------------- 604.2/977.5 kB 413.0 kB/s eta 0:00:01\n",
            "   ----------------------- -------------- 614.4/977.5 kB 402.8 kB/s eta 0:00:01\n",
            "   ------------------------ ------------- 634.9/977.5 kB 395.8 kB/s eta 0:00:01\n",
            "   ------------------------ ------------- 634.9/977.5 kB 395.8 kB/s eta 0:00:01\n",
            "   ------------------------- ------------ 665.6/977.5 kB 392.0 kB/s eta 0:00:01\n",
            "   ------------------------- ------------ 665.6/977.5 kB 392.0 kB/s eta 0:00:01\n",
            "   ------------------------- ------------ 665.6/977.5 kB 392.0 kB/s eta 0:00:01\n",
            "   -------------------------- ----------- 686.1/977.5 kB 379.5 kB/s eta 0:00:01\n",
            "   --------------------------- ---------- 696.3/977.5 kB 369.1 kB/s eta 0:00:01\n",
            "   --------------------------- ---------- 696.3/977.5 kB 369.1 kB/s eta 0:00:01\n",
            "   --------------------------- ---------- 716.8/977.5 kB 367.6 kB/s eta 0:00:01\n",
            "   ---------------------------- --------- 727.0/977.5 kB 364.0 kB/s eta 0:00:01\n",
            "   ----------------------------- -------- 747.5/977.5 kB 363.0 kB/s eta 0:00:01\n",
            "   ----------------------------- -------- 768.0/977.5 kB 364.7 kB/s eta 0:00:01\n",
            "   ------------------------------ ------- 778.2/977.5 kB 361.4 kB/s eta 0:00:01\n",
            "   ------------------------------- ------ 798.7/977.5 kB 365.7 kB/s eta 0:00:01\n",
            "   ------------------------------- ------ 809.0/977.5 kB 362.6 kB/s eta 0:00:01\n",
            "   --------------------------------- ---- 849.9/977.5 kB 368.1 kB/s eta 0:00:01\n",
            "   --------------------------------- ---- 860.2/977.5 kB 365.1 kB/s eta 0:00:01\n",
            "   ---------------------------------- --- 880.6/977.5 kB 366.5 kB/s eta 0:00:01\n",
            "   ---------------------------------- --- 890.9/977.5 kB 363.6 kB/s eta 0:00:01\n",
            "   ------------------------------------ - 931.8/977.5 kB 371.0 kB/s eta 0:00:01\n",
            "   ------------------------------------ - 942.1/977.5 kB 370.4 kB/s eta 0:00:01\n",
            "   -------------------------------------  962.6/977.5 kB 373.9 kB/s eta 0:00:01\n",
            "   -------------------------------------- 977.5/977.5 kB 368.5 kB/s eta 0:00:00\n",
            "Installing collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZn90DrGtSdJ"
      },
      "source": [
        "# **BPE IMPLEMENT vocab size 1K**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl-l7Hvco7Kw",
        "outputId": "0763122c-5887-4c9b-bbdd-82ae4dc3d3ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** BPE ***\n"
          ]
        }
      ],
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "# Train SentencePiece model\n",
        "spm.SentencePieceTrainer.train('--input=gu_100.txt --model_prefix=m_bpe --vocab_size=1000 --model_type=bpe')\n",
        "\n",
        "# Load the trained model\n",
        "sp_bpe = spm.SentencePieceProcessor()\n",
        "sp_bpe.load('m_bpe.model')\n",
        "\n",
        "# Tokenize text from 'temp.txt' file\n",
        "print('*** BPE ***')\n",
        "with open('gu_100.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "with open('ques_25.txt', 'r', encoding='utf-8') as file:\n",
        "    text2 = file.read()\n",
        "\n",
        "ques_25_bpe=sp_bpe.encode_as_pieces(text2)\n",
        "bpe_list=sp_bpe.encode_as_pieces(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjXk8xGuqg8a",
        "outputId": "720bd493-1659-42e1-baa4-1847a0e66ac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('છે', 320962), ('ક', 245518), ('ના', 233379), ('ન', 230649), ('મ', 214983), ('ર', 208924), ('સ', 199487), ('માં', 191089), ('લ', 187060), ('ની', 172030), ('જ', 171312), ('આ', 170013), ('ને', 164128), ('પ', 156578), ('અને', 155795), ('ત', 152201), ('એ', 147101), ('વ', 146401), ('વા', 143643), ('ટ', 137690)]\n",
            "['ડિ', 'સ્', 'પ્', 'લે', 'પર', 'પણ', 'યા', 'ંત્ર', 'િક', 'ન', 'ુક', 'સ', 'ાન', 'કો', 'ર્', 'ન', 'િંગ', 'ગ', '્', 'લા', 'સ', 'થી', 'એક', 'ખાસ', 'ર', 'ક્ષ', 'ણા', 'ત્', 'મક', 'સ્', 'તર', 'છે', '4', '(', 'ઇ', '1', 'પા', 'કિ', 'સ્તા', 'નના', 'પી', 'એ', 'મ', 'ઈ', 'મ', 'રા', 'ન', 'ખ', 'ાન', 'ની', 'અધ', '્ય', 'ક્ષ', 'તા', 'માં', 'આ', 'બેઠ', 'ક', 'બો', 'લા', 'વ', 'વામાં', 'આવી', 'છે', 'આવી', 'ઘટના', 'માં', 'છે', 'તર', 'પ', 'િ', 'ં', 'ડી', 'કર', 'નાર', 'વ્યક્તિ', 'મો', 'ટે', 'ભા', 'ગે', 'પરિ', 'ચ', 'િત', 'અથવા', 'તો', 'સંબંધ', 'ી', 'હોય', 'છે', 'એ', 'વાત', 'વધ', 'ારે', 'આ', 'ઘ', 'ા', 'ત', 'જન', 'ક', 'હોય', 'છે', 'આ', 'પ', 'તા', 'વ', 'ટ', 'ની', 'આ', 'ંત', 'ર', 'મા', 'ળ', 'ખા', 'ખૂબ', 'સારી', 'રીતે', 'વિક', 'સ', 'િત', 'નથી', 'આ', 'ર', 'ક', 'મ', 'આ', 'શ', 'રે', 'છે', 'અમે', 'આ', 'મા', 'મ', 'લે', 'બહાર', 'નાં', 'વ્યક્તિ', 'નાં', 'કોઇ', 'પણ', 'દા', 'વા', 'ને', 'સંપૂર્ણ', 'રીતે', 'ફ', 'ગા', 'વી', 'એ', 'છ', 'ીએ', '', '-', 'આ', 'કિ', 'સ્', 'સા', 'ઓમાં', 'એ', 'ન્ટ', 'િ', 'બ', 'ાયો', 'ટ', 'િ', 'ક્સ', 'સાથે', 'સાર', 'વાર', 'જરૂર', 'છે', 'તમારી', 'રા', 'શિ', 'ના', 'લોકો', 'એ', 'હા', 'લ', 'દુ', 'ર્', 'ઘ', 'ટના', 'ઓ', 'થી', 'સા', 'વ', 'ધાન', 'રહે', 'વાની', 'જરૂર', 'છે', 'આ', 'બા', 'બ', 'ત', 'છે', 'ત', '્ય', 'ાર', 'બા', 'દ', 'સી', 'બી', 'આ', 'ઇ', 'અને', 'ઇ', 'ડી', 'એ', 'પ', 'ૂર', 'ક', 'ચ', 'ાર્', 'જ', 'શી', 'ટ', 'દા', 'ખ', 'લ', 'કરી', 'હતી', '.', 'ઈ', 'ન્ડ', 'િયન', 'આ', 'ઈ', 'ડ', 'લ', '1', 'ના', 'આગ', 'ામી', 'એ', 'પ', 'િ', 'સો', 'ડ', 'માં', 'ઉ', 'દ', 'િત', 'ના', 'રા', 'ય', 'ણ', 'અને', 'અલ', 'કા', 'યા', 'જ્', 'ઞ', 'િક', 'મ', 'હે', 'માન', 'બન', 'શે', 'જ્યારે', 'ક્', 'લે', 'ર', 'િસ', 'અને', 'મ', 'િત', '્સ', 'ુ', 'ઇ', 'નો', 'સ', 'માન', 'હિ', 'સ્', 'સો', 'હતો', 'આ', 'થી', '', 'ઋ', 'ષ', 'િક', 'ેશ', 'ન', 'ગ', 'રમાં', 'વિ', 'ર', 'ભ', 'દ', '્ર', 'બંધ', 'ના', 'દ્વા', 'ર', 'પાસે', 'તે', 'ફ', 'સા', 'ઈ', 'ગ', 'યો', 'હતો', 'ઉ', 'રી', 'હ', 'ુ', 'મ', 'લા', 'પછી', 'ભાર', 'તીય', 'સે', 'ના', 'તરફ', 'થી', 'સર્', 'જ', 'િક', 'લ', 'સ્ટ', '્રા', 'ઇ', 'ક', 'કરવામાં', 'આવી', 'આ', 'ખૂબ', 'જ', 'ખ', 'તર', 'ના', 'ક', 'મિ', 'શન', 'ને', 'સફ', 'ળ', 'તા', 'પૂર્', 'વ', 'ક', 'પ', 'ાર', 'પા', 'ડ', 'વાનો', 'શ્રે', 'ય', 'જાય', 'છે', 'ભારત', 'ના', 'રા', 'ષ્ટ', '્રી', 'ય', 'સુ', 'ર', 'ક્ષા', 'સ', 'લા', 'હ', 'કાર', 'અ', 'જી', 'ત', 'ડો', 'વા', 'લ', 'વ્યા', 'પ', 'ક', 'દર', 'િયા', 'કિ', 'ના', 'રો', 'જે', 'ના', 'માટે', 'સર', 'ક', 'ારે', 'ઘણી', 'બ', 'ધી', 'યો', 'જના', 'ઓ', 'પણ', 'ઘ', 'ડી', 'છે', 'કે', 'ખે', 'ડ', 'ૂ', 'તો', 'ને', 'થો', 'ડા', 'ઘણા', 'અ', 'ં', 'શે', 'પોતાની', 'ત', 'ક', 'લી', 'ફ', 'માં', 'રા', 'હ', 'ત', 'મળી', 'રહે', 'સ્', 'પે', 'ન્સ', 'રી', 'સ', 'શિ', 'ષ', '્ય', 'વ', 'ૃ', 'ત્', 'તિ', 'જો', 'તમે', 'સ', 'લ્', 'ફ', 'રમાં', 'થી', 'સામ', 'ય', 'િક', 'ટે', 'બ', 'લ', 'ને', 'ની', 'ચે', 'ખ', 'સે', 'ડો', 'તેમણે', 'કરો', 'ડો', 'પ', 'તિ', 'નો', 'દર', 'જ્', 'જો', 'પ્રા', 'પ્ત', 'કર્યો', 'છે', 'કારણ', 'કે', 'તેઓ', 'એ', 'સ', 'ત', 'ત', 'ઘણી', 'સં', 'પ', 'ત્', 'તિ', 'નિર્', 'મા', 'ણ', 'ની', 'વ્ય', 'ૂ', 'હ', 'ર', 'ચના', 'ઓ', 'નો', 'ઉપયોગ', 'કર્યો', 'છે', 'કે', 'જે', 'માંથી', 'કોઈ', 'પણ', 'ઉપયોગ', 'કરી', 'શકે', 'છે', 'આજે', 'થી', 'શરૂ', 'અહીં', 'આગ', 'ામી', 'બ', 'ારો', 'માંથી', 'મ', 'િલ', 'િય', 'ને', 'રના', 'બ', 'ાર', 'લ', 'ક્ષ', 'ણો', 'છે', 'પ', 'ટ', 'પ', 'ટ', 'તી', 'પા', 'પ', 'ણો', ':', 'લોકો', 'કા', 'દ', 'વ', 'માં', 'ન', 'હો', 'ઈ', 'શકે', 'આ', 'લે', 'ખ', 'માં', 'અમે', 'તમને', 'ક', 'હી', 'શ', 'ું', 'કે', 'સ્', 'વિ', 'મ', 'િંગ', 'ને', 'વધુ', 'ર', 'સ', 'પ્ર', 'દ', 'વધુ', 'ખાસ', 'બા', 'ંધ', 'કા', 'મ', 'મિ', 'શ', '્રણ', 'વા', 'પ', 'રી', 'ને', 'મા', 'ળ', 'ભ', 'ર', 'વા', 'એક', 'મો', 'ટી', 'સો', 'દો', 'નથી', 'માર્', 'કે', 'ટ', 'વે', 'લ', '્યુ', 'ની', 'દ', '્ર', 'ષ્ટ', 'િ', 'એ', 'કો', 'ટ', 'ક', 'મહિ', 'ન્દ', '્રા', 'બે', 'ંક', 'એ', 'ચ', 'ડી', 'એ', 'ફ', 'સી', 'બાદ', 'બીજા', 'ન', 'ં', 'બર', 'ની', '.', '.', '', 'એ', 'એ', 'ફ', 'ડી', 'ના', 'વ્યા', 'જ', 'દ', 'રમાં', '', 'ટકા', 'સુધી', 'નો']\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "\n",
        "tokens_cleaned = [token.replace('▁', '') for token in bpe_list if token not in punctuation_list ]\n",
        "ques_25_cleaned_bpe = [token.replace('▁', '') for token in ques_25_bpe if token not in punctuation_list ]\n",
        "\n",
        "# Count the frequency of each token\n",
        "token_freq = Counter(tokens_cleaned)\n",
        "\n",
        "bpe_token_freq_list = list(token_freq.items())\n",
        "# print(token_freq_list)\n",
        "bpe_sorted_token_freq_list = sorted(bpe_token_freq_list, key=lambda x: x[1], reverse=True)\n",
        "print(bpe_sorted_token_freq_list[:20])\n",
        "print(ques_25_cleaned_bpe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QqT_L-N53MM"
      },
      "source": [
        "# bigram of **Tokenizer function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyeIvTbO7R4j"
      },
      "outputs": [],
      "source": [
        "def get_bigramTokenizer_frequency(tokens_cleaned):\n",
        "    biagram_token_list = []\n",
        "    for i in range(len(tokens_cleaned) - 1):\n",
        "        pair = tokens_cleaned[i] + \" \" + tokens_cleaned[i+1]\n",
        "        biagram_token_list.append(pair)\n",
        "\n",
        "\n",
        "\n",
        "    bigram_token_frequency = {}\n",
        "    i = 0\n",
        "    while i < len(biagram_token_list):\n",
        "        ch = biagram_token_list[i]\n",
        "        bigram_token_frequency[ch] = bigram_token_frequency.get(ch, 0) + 1\n",
        "        i += 1\n",
        "\n",
        "    sort_bigram_token_list = [(bisyllable, count) for bisyllable, count in bigram_token_frequency.items()]\n",
        "    sort_bigram_token_list.sort(key=lambda x: x[1], reverse=True)\n",
        "    return sort_bigram_token_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zv2Cdeo-oPf"
      },
      "source": [
        "# biagram of **Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hapAgQi-TDI",
        "outputId": "95933fc1-29ce-40a9-c5e6-4f20852e57a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('છે કે', 25798), ('છે અને', 20969), ('છે આ', 18521), ('આવે છે', 17157), ('શકે છે', 15791), ('કરે છે', 15645), ('છે જે', 15114), ('વા માટે', 14418), ('છે તે', 12795), (' ', 11628), ('કરવા માટે', 11534), ('થાય છે', 10613), ('વામાં આવે', 10483), ('હોય છે', 10025), ('શકો છો', 8813), ('વે છે', 7701), ('છે ', 7523), ('છે પરંતુ', 7420), ('ે છે', 7213), ('જો કે', 7196)]\n"
          ]
        }
      ],
      "source": [
        "bigram_token_list=[]\n",
        "bigram_token_list_sorted=[]\n",
        "bigram_token_list_sorted=get_bigramTokenizer_frequency(tokens_cleaned)\n",
        "print(bigram_token_list_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjxhTy5riJRi"
      },
      "source": [
        "# unigram and bigram of **character**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5JhPtv-Zk3H"
      },
      "outputs": [],
      "source": [
        "processed_words_bpe_1000 = [] # list contain all the corrected unicode\n",
        "\n",
        "\n",
        "    # Process each word and store cleaned versions\n",
        "for word in tokens_cleaned:\n",
        "  cleaned_word = correct_unicode(word)  # Explain what this function does\n",
        "  processed_words_bpe_1000.append(cleaned_word)\n",
        "        # print(f\"{word} => {cleaned_word}\")\n",
        "\n",
        "    # Increment the counter\n",
        "    # counter += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MDvurFDaMme",
        "outputId": "e77b261a-9326-45a5-803e-8dfe5fdbce78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '', ' મ્ ઈ', ' ઓ', ' ગ્ અ', ' સ્ ટ્ અ', '', '', '', '']\n"
          ]
        }
      ],
      "source": [
        "N = 10\n",
        "result=[]\n",
        "result = processed_words_bpe_1000[:N]\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8JetCCmfC4d"
      },
      "source": [
        "**unigram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHxR0hGvagvy"
      },
      "outputs": [],
      "source": [
        "unigram_char_list_bpe_1000=[]\n",
        "\n",
        "unigram_char_list_bpe_1000_sorted=[]\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "for word in processed_words_bpe_1000:\n",
        "\n",
        "  unigram_for_char(word, vyanjan,unigram_char_list_bpe_1000) # unigram for character\n",
        "\n",
        "  # print(\" unigram characters \")\n",
        "\n",
        "unigram_char_list_bpe_1000_sorted=sort_list_by_frequency(unigram_char_list_bpe_1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8nuD1BEe6Wl",
        "outputId": "b33fb37f-9e71-414d-af38-2bfc1f2a69ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ', 8685641), ('આ', 3371031), ('એ', 2413912), ('ર્', 2128526), ('ન્', 1734112), ('ઈ', 1505521), ('ક્', 1386555), ('મ્', 1324843), ('ત્', 1207724), ('વ્', 1149790), ('ઓ', 1149632), ('સ્', 976491), ('પ્', 867048), ('ય્', 745130), ('લ્', 684911), ('જ્', 585042), ('ઉ', 539474), ('ટ્', 520557), ('હ્', 516880), ('ઇ', 503000)]\n"
          ]
        }
      ],
      "source": [
        "print(unigram_char_list_bpe_1000_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSveElDvfHv4"
      },
      "source": [
        "**bigram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv0kOJ-KfFXJ",
        "outputId": "e25e120b-4f38-481d-af49-884755f6da52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર્અ', 1106805), ('ક્અ', 724968), ('અર', 582265), ('મ્આ', 578596), ('પ્અ', 476944), ('મ્અ', 469870), ('સ્અ', 464575), ('ન્અ', 444891), ('ત્અ', 423454), ('વ્આ', 403405), ('વ્અ', 382561), ('ન્એ', 374087), ('અન', 347885), ('ન્આ', 338777), ('ય્અ', 335017), ('છ્એ', 320962), ('ટ્અ', 308164), ('ગ્અ', 275400), ('જ્અ', 263405), ('લ્અ', 259627)]\n"
          ]
        }
      ],
      "source": [
        "bigram_char_list_bpe_1000=[]\n",
        "\n",
        "bigram_char_list_bpe_1000_sorted=[]\n",
        "\n",
        "from collections import Counter\n",
        "for word in processed_words_bpe_1000:\n",
        "   bigram_for_char(word, vyanjan,bigram_char_list_bpe_1000) # bigram for character\n",
        "bigram_char_list_bpe_1000_sorted=sort_list_by_frequency(bigram_char_list_bpe_1000)\n",
        "print(bigram_char_list_bpe_1000_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-J5mKz3iCBn"
      },
      "source": [
        "# unigram and bigram of **syllable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TykUTkrfiAj_"
      },
      "outputs": [],
      "source": [
        "unigram_syllables_list_bpe_1000=[]\n",
        "unigram_syllabless=[]\n",
        "unigram_syllables_list_sorted_bpe_1000=[]\n",
        "swapped_dict = {v: k for k, v in gujarati_dict.items()}\n",
        "\n",
        "# print(swapped_dict)\n",
        "# resullt = [' મ્ ઈ', ' ઓ ગ્ અ સ્ ટ્ અ', ' ન્ આ']\n",
        "spchar = '@'\n",
        "count =0\n",
        "for word in processed_words_bpe_1000:\n",
        "\n",
        "  unigram_syllables(word,swar,vyanjan,swapped_dict,unigram_syllables_list_bpe_1000,unigram_syllabless)\n",
        "  unigram_syllabless.append(spchar)\n",
        "\n",
        "\n",
        "\n",
        "unigram_syllables_list_sorted_bpe_1000=sort_list_by_frequency(unigram_syllables_list_bpe_1000)\n",
        "# print(unigram_syllabless)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiBeTXLcjast",
        "outputId": "f053452a-0973-4bfd-d74c-fee9b55a10c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર', 928948), ('ક', 716071), ('મા', 578596), ('મ', 457069), ('પ', 455178), ('ન', 444891), ('સ', 422172), ('ત', 397141), ('વા', 384305), ('ને', 369879), ('વ', 362845), ('અ', 354831), ('ના', 338777), ('આ', 331134), ('છે', 320962), ('ય', 271111), ('ગ', 270471), ('જ', 263405), ('લ', 259627), ('એ', 250862)]\n"
          ]
        }
      ],
      "source": [
        "print(unigram_syllables_list_sorted_bpe_1000[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5Iwae_wjr8N",
        "outputId": "4294ab83-8e41-448a-c03a-ec63977ebaec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ ને', 155795), ('ક ર', 113511), ('પ ર', 90567), ('મા ટે', 83880), ('એ ક', 70724), ('પ ણ', 59736), ('કા ર', 56880), ('ક રી', 56610), ('વા મા', 56142), ('ર વા', 55329), ('સા થે', 45106), ('તે મ', 42620), ('સ મ', 38367), ('સ ં', 33918), ('હ તી', 32761), ('ઉ પ', 31354), ('ત મા', 30862), ('ન થી', 30440), ('આ પ', 28436), ('આ વે', 28185)]\n"
          ]
        }
      ],
      "source": [
        "bigram_syllables_list_bpe_1000=[]\n",
        "bigram_syllables_list_sorted_bpe_1000=[]\n",
        "bigram_syllables_list_sorted_bpe_1000=get_bisyllable_frequency(unigram_syllabless,bigram_syllables_list_bpe_1000)\n",
        "print(bigram_syllables_list_sorted_bpe_1000[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XKGAtm4wiK3"
      },
      "source": [
        "# **BPE IMPLEMENT vocab size 2K**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-CVw1n4Iyug",
        "outputId": "1224a9ed-2c67-44e3-ce08-4527bfcf1c3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spm.SentencePieceTrainer.train('--input=gu_100.txt --model_prefix=m_bpe --vocab_size=2000 --model_type=bpe')\n",
        "# Load the trained model\n",
        "sp_bpe = spm.SentencePieceProcessor()\n",
        "sp_bpe.load('m_bpe.model')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89zYqR6wwl0J",
        "outputId": "4b384d45-aa71-473f-95bf-3a391a85e68e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** BPE ***\n"
          ]
        }
      ],
      "source": [
        "# Tokenize text from 'temp.txt' file\n",
        "print('*** BPE ***')\n",
        "with open('gu_100.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "bpe_list=sp_bpe.encode_as_pieces(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azPT5Vhkwm0i",
        "outputId": "3c7c7423-7e4a-4259-b272-93eaecc84c6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('છે', 318182), ('ના', 190463), ('માં', 159786), ('અને', 152221), ('ની', 149348), ('ક', 149044), ('ન', 135263), ('ને', 129092), ('આ', 128648), ('જ', 124456), ('લ', 113825), ('કે', 113658), ('સ', 110405), ('ર', 107510), ('મ', 104554), ('એ', 104391), ('ત', 90513), ('માટે', 83880), ('બ', 82363), ('પ', 82173)]\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "\n",
        "tokens_cleaned_vocab_2000 = [token.replace('▁', '') for token in bpe_list if token not in punctuation_list ]\n",
        "\n",
        "# Count the frequency of each token\n",
        "token_freq = Counter(tokens_cleaned_vocab_2000)\n",
        "\n",
        "bpe_token_freq_list = list(token_freq.items())\n",
        "# print(token_freq_list)\n",
        "bpe_sorted_token_freq_list = sorted(bpe_token_freq_list, key=lambda x: x[1], reverse=True)\n",
        "print(bpe_sorted_token_freq_list[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YA5GXsv-8z3"
      },
      "source": [
        "# biagram of **Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQVp6M6q-7nW",
        "outputId": "20f16d0b-50ef-467a-c498-2d0f27c76260"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('છે કે', 25329), ('છે અને', 20846), ('આવે છે', 17156), ('છે આ', 16504), ('શકે છે', 15787), ('કરે છે', 15643), ('છે જે', 11542), ('કરવા માટે', 11534), ('છે તે', 10854), ('થાય છે', 10611), ('હોય છે', 10023), ('વા માટે', 9087), ('શકો છો', 8813), ('છે પરંતુ', 7412), ('વામાં આવે', 6728), ('. .', 6317), ('કારણ કે', 6221), ('રહી છે', 5841), ('કરવામાં આવે', 5793), ('હતું કે', 5733)]\n"
          ]
        }
      ],
      "source": [
        "bigram_token_list_bpe_2000=[]\n",
        "bigram_token_list_bpe_2000_sorted=[]\n",
        "bigram_token_list_bpe_2000_sorted=get_bigramTokenizer_frequency(tokens_cleaned_vocab_2000)\n",
        "print(bigram_token_list_bpe_2000_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY7Q-uzdk5Ul"
      },
      "source": [
        "# unigram and bigram of **character**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DChrzTLkmxV"
      },
      "outputs": [],
      "source": [
        "processed_words_bpe_2000 = [] # list contain all the corrected unicode\n",
        "\n",
        "\n",
        "    # Process each word and store cleaned versions\n",
        "for word in tokens_cleaned:\n",
        "  cleaned_word = correct_unicode(word)  # Explain what this function does\n",
        "  processed_words_bpe_2000.append(cleaned_word)\n",
        "        # print(f\"{word} => {cleaned_word}\")\n",
        "\n",
        "    # Increment the counter\n",
        "    # counter += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj1-UmrekyaJ",
        "outputId": "5261187a-3c48-4379-aade-91f712fb453b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '', ' મ્ ઈ', ' ઓ', ' ગ્ અ', ' સ્ ટ્ અ', '', '', '', '']\n"
          ]
        }
      ],
      "source": [
        "N = 10\n",
        "result=[]\n",
        "result = processed_words_bpe_2000[:N]\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMzMt8a9ld2W"
      },
      "source": [
        "**unigram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kg1KSXZ1k8Iy"
      },
      "outputs": [],
      "source": [
        "unigram_char_list_bpe_2000=[]\n",
        "\n",
        "unigram_char_list_bpe_2000_sorted=[]\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "for word in processed_words_bpe_2000:\n",
        "\n",
        "  unigram_for_char(word, vyanjan,unigram_char_list_bpe_2000) # unigram for character\n",
        "\n",
        "  # print(\" unigram characters \")\n",
        "\n",
        "unigram_char_list_bpe_2000_sorted=sort_list_by_frequency(unigram_char_list_bpe_2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7utqSL-glPlc",
        "outputId": "d5e4ddf0-5d90-4ef9-97ed-c44c67d3d3fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ', 8685641), ('આ', 3371031), ('એ', 2413912), ('ર્', 2128526), ('ન્', 1734112), ('ઈ', 1505521), ('ક્', 1386555), ('મ્', 1324843), ('ત્', 1207724), ('વ્', 1149790), ('ઓ', 1149632), ('સ્', 976491), ('પ્', 867048), ('ય્', 745130), ('લ્', 684911), ('જ્', 585042), ('ઉ', 539474), ('ટ્', 520557), ('હ્', 516880), ('ઇ', 503000)]\n"
          ]
        }
      ],
      "source": [
        "print(unigram_char_list_bpe_2000_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRuQEFqRlbHQ"
      },
      "source": [
        "**bigram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4AanaHklRF6",
        "outputId": "ab148ef3-5685-4027-8b6a-f00722fd8d5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર્અ', 1106805), ('ક્અ', 724968), ('અર', 582265), ('મ્આ', 578596), ('પ્અ', 476944), ('મ્અ', 469870), ('સ્અ', 464575), ('ન્અ', 444891), ('ત્અ', 423454), ('વ્આ', 403405), ('વ્અ', 382561), ('ન્એ', 374087), ('અન', 347885), ('ન્આ', 338777), ('ય્અ', 335017), ('છ્એ', 320962), ('ટ્અ', 308164), ('ગ્અ', 275400), ('જ્અ', 263405), ('લ્અ', 259627)]\n"
          ]
        }
      ],
      "source": [
        "bigram_char_list_bpe_2000=[]\n",
        "\n",
        "bigram_char_list_bpe_2000_sorted=[]\n",
        "\n",
        "from collections import Counter\n",
        "for word in processed_words_bpe_2000:\n",
        "   bigram_for_char(word, vyanjan,bigram_char_list_bpe_2000) # bigram for character\n",
        "bigram_char_list_bpe_2000_sorted=sort_list_by_frequency(bigram_char_list_bpe_2000)\n",
        "print(bigram_char_list_bpe_2000_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKOBQnsTlmT4"
      },
      "source": [
        "# unigram and bigram of **syllable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNTZKkjClh55"
      },
      "outputs": [],
      "source": [
        "unigram_syllables_list_bpe_2000=[]\n",
        "unigram_syllabless=[]\n",
        "unigram_syllables_list_sorted_bpe_2000=[]\n",
        "swapped_dict = {v: k for k, v in gujarati_dict.items()}\n",
        "\n",
        "# print(swapped_dict)\n",
        "# resullt = [' મ્ ઈ', ' ઓ ગ્ અ સ્ ટ્ અ', ' ન્ આ']\n",
        "spchar = '@'\n",
        "count =0\n",
        "for word in processed_words_bpe_2000:\n",
        "\n",
        "  unigram_syllables(word,swar,vyanjan,swapped_dict,unigram_syllables_list_bpe_2000,unigram_syllabless)\n",
        "  unigram_syllabless.append(spchar)\n",
        "\n",
        "\n",
        "\n",
        "unigram_syllables_list_sorted_bpe_2000=sort_list_by_frequency(unigram_syllables_list_bpe_2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pO5IFjLulx4k",
        "outputId": "c50dc0c8-0378-4982-bbce-d6ddcfc1b25a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર', 928948), ('ક', 716071), ('મા', 578596), ('મ', 457069), ('પ', 455178), ('ન', 444891), ('સ', 422172), ('ત', 397141), ('વા', 384305), ('ને', 369879), ('વ', 362845), ('અ', 354831), ('ના', 338777), ('આ', 331134), ('છે', 320962), ('ય', 271111), ('ગ', 270471), ('જ', 263405), ('લ', 259627), ('એ', 250862)]\n"
          ]
        }
      ],
      "source": [
        "print(unigram_syllables_list_sorted_bpe_2000[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoVGh_aUl8c6",
        "outputId": "d3ad9ec9-12e3-4f9a-8347-89ef80d03c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ ને', 155795), ('ક ર', 113511), ('પ ર', 90567), ('મા ટે', 83880), ('એ ક', 70724), ('પ ણ', 59736), ('કા ર', 56880), ('ક રી', 56610), ('વા મા', 56142), ('ર વા', 55329), ('સા થે', 45106), ('તે મ', 42620), ('સ મ', 38367), ('સ ં', 33918), ('હ તી', 32761), ('ઉ પ', 31354), ('ત મા', 30862), ('ન થી', 30440), ('આ પ', 28436), ('આ વે', 28185)]\n"
          ]
        }
      ],
      "source": [
        "bigram_syllables_list_bpe_2000=[]\n",
        "bigram_syllables_list_sorted_bpe_2000=[]\n",
        "bigram_syllables_list_sorted_bpe_2000=get_bisyllable_frequency(unigram_syllabless,bigram_syllables_list_bpe_2000)\n",
        "print(bigram_syllables_list_sorted_bpe_2000[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrqGb9vbFt1Q"
      },
      "source": [
        "# **Unigram**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOEoPsiuJgsa",
        "outputId": "59c74e9a-5e8a-4e52-bb2f-0f17d359deaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sentencepiece as spm\n",
        "spm.SentencePieceTrainer.train('--input=gu_100.txt --model_prefix=m_unigram --model_type=unigram')\n",
        "sp_unigram = spm.SentencePieceProcessor()\n",
        "sp_unigram.load('m_unigram.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFqxkdpeujfj",
        "outputId": "60823b4e-5f6c-4a3f-d936-b0cc5cff8280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** Unigram ***\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "print('*** Unigram ***')\n",
        "with open('gu_100.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "with open('ques_25.txt', 'r', encoding='utf-8') as file:\n",
        "    text2 = file.read()\n",
        "\n",
        "ques_25_unigram=sp_unigram.encode_as_pieces(text2)\n",
        "unigram_list=sp_unigram.encode_as_pieces(text)\n",
        "# print(unigram_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjR8h3JLvFjo",
        "outputId": "44f44092-1aa8-4130-dc4b-2e9f3f02cba1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('છે', 317043), ('ના', 153495), ('અને', 152789), ('માં', 151459), ('ની', 146872), ('ને', 112305), ('આ', 99947), ('કે', 92217), ('માટે', 83880), ('એ', 66163), ('એક', 66111), ('જ', 62438), ('નો', 61701), ('તે', 61374), ('ન', 60366), ('પર', 56761), ('', 56070), ('પણ', 55206), ('ર', 50706), ('થી', 50541)]\n",
            "['ડિસ્પ્લે', 'પર', 'પણ', 'યાંત્રિક', 'નુકસાન', 'કો', 'ર્ન', 'િંગ', 'ગ્લાસ', 'થી', 'એક', 'ખાસ', 'રક્ષણાત્મક', 'સ્તર', 'છે', '4', '(', '20', '17', 'ઇ', '12', '70', 'પાકિસ્તાનના', 'પીએમ', 'ઈમરાન', 'ખાન', 'ની', 'અધ્યક્ષ', 'તા', 'માં', 'આ', 'બેઠક', 'બોલાવવા', 'માં', 'આવી', 'છે', 'આવી', 'ઘટના', 'માં', 'છેતરપિંડી', 'કરનાર', 'વ્યક્તિ', 'મોટે', 'ભાગે', 'પરિચિત', 'અથવા', 'તો', 'સંબંધી', 'હોય', 'છે', 'એ', 'વાત', 'વધારે', 'આઘાત', 'જનક', 'હોય', 'છે', 'આ', 'પ', 'તા', 'વ', 'ટ', 'ની', 'આંતર', 'મા', 'ળ', 'ખા', 'ખૂબ', 'સારી', 'રીતે', 'વિકસિત', 'નથી', 'આ', 'રકમ', 'આશરે', 'છે', 'અમે', 'આ', 'મામલે', 'બહાર', 'નાં', 'વ્યક્તિ', 'નાં', 'કોઇ', 'પણ', 'દાવા', 'ને', 'સંપૂર્ણ', 'રીતે', 'ફગાવી', 'એ', 'છીએ', ')', '-', 'આ', 'કિસ્સાઓમાં', 'એન્ટિ', 'બ', 'ાયો', 'ટ', 'િક્સ', 'સાથે', 'સારવાર', 'જરૂર', 'છે', 'તમારી', 'રાશિ', 'ના', 'લોકોએ', 'હાલ', 'દુર્ઘટના', 'ઓ', 'થી', 'સાવ', 'ધાન', 'રહેવાની', 'જરૂર', 'છે', 'આ', 'બાબત', 'છે', 'ત્યારબાદ', 'સીબીઆઇ', 'અને', 'ઇ', 'ડી', 'એ', 'પૂરક', 'ચાર્જ', 'શી', 'ટ', 'દાખલ', 'કરી', 'હતી', '.', 'ઈન્ડિયન', 'આ', 'ઈડ', 'લ', '11', 'ના', 'આગામી', 'એપિસોડ', 'માં', 'ઉ', 'દ', 'િત', '', 'નારાયણ', 'અને', 'અલ', 'કા', 'યા', 'જ્ઞ', 'િક', 'મહેમાન', 'બનશે', 'જ્યારે', 'ક્લે', 'ર', 'િસ', 'અને', 'મ', 'િત', '્સ', 'ુ', 'ઇ', 'નો', 'સમાન', 'હિસ્સો', 'હતો', 'આ', 'થી', '', 'ઋ', 'ષ', 'િક', 'ેશ', 'નગર', 'માં', 'વિ', 'ર', 'ભદ્ર', 'બંધ', 'ના', 'દ્વાર', 'પાસે', 'તે', 'ફસાઈ', 'ગયો', 'હતો', 'ઉ', 'રી', 'હુમલા', 'પછી', 'ભારતીય', 'સેના', 'તરફથી', 'સર્જ', 'િકલ', 'સ્ટ્રાઇક', 'કરવામાં', 'આવી', 'આ', 'ખૂબ', 'જ', 'ખતરનાક', 'મિશન', 'ને', 'સફળતા', 'પૂર્વ', 'ક', 'પાર', 'પાડવા', 'નો', 'શ્રેય', 'જાય', 'છે', 'ભારતના', 'રાષ્ટ્રીય', 'સુરક્ષા', 'સલાહકાર', 'અ', 'જીત', 'ડો', 'વા', 'લ', 'વ્યાપક', 'દરિયા', 'કિ', 'ના', 'રો', 'જેના', 'માટે', 'સરકારે', 'ઘણી', 'બધી', 'યોજનાઓ', 'પણ', 'ઘડી', 'છે', 'કે', 'ખેડૂતો', 'ને', 'થોડા', 'ઘણા', 'અંશે', 'પોતાની', 'તકલીફ', 'માં', 'રાહત', 'મળી', 'રહે', 'સ્પે', 'ન્સ', 'રી', 'સ', 'શિષ્ય', 'વૃત્તિ', 'જો', 'તમે', 'સલ્ફ', 'ર', 'માંથી', 'સામયિક', 'ટેબલ', 'ને', 'નીચે', 'ખસે', 'ડો', 'તેમણે', 'કરોડો', 'પતિ', 'નો', 'દરજ્જો', 'પ્રાપ્ત', 'કર્યો', 'છે', 'કારણ', 'કે', 'તેઓ', 'એ', 'સતત', 'ઘણી', 'સંપત્તિ', 'નિર્માણ', 'ની', 'વ્યૂહરચના', 'ઓનો', 'ઉપયોગ', 'કર્યો', 'છે', 'કે', 'જેમાંથી', 'કોઈ', 'પણ', 'ઉપયોગ', 'કરી', 'શકે', 'છે', 'આજે', 'થી', 'શરૂ', 'અહીં', 'આગામી', 'બાર', 'ો', 'માંથી', 'મિલિયન', 'ે', 'ર', 'ના', 'બાર', 'લક્ષણો', 'છે', 'પટ', 'પટ', 'તી', 'પાપ', 'ણો', ':', 'લોકો', 'કાદવ', 'માં', 'ન', 'હોઈ', 'શકે', 'આ', 'લેખમાં', 'અમે', 'તમને', 'કહી', 'શું', 'કે', 'સ્વિમિંગ', 'ને', 'વધુ', 'રસપ્રદ', 'વધુ', 'ખાસ', 'બાંધકામ', 'મિશ્રણ', 'વાપરી', 'ને', 'માળ', 'ભરવા', 'એક', 'મોટી', 'સોદો', 'નથી', 'માર્કેટ', 'વેલ', '્યુ', 'ની', 'દ્રષ્ટિએ', 'કોટ', 'ક', 'મહિન્દ્રા', 'બેંક', 'એચડી', 'એફ', 'સી', 'બાદ', 'બીજા', 'નંબર', 'ની', '.', '.', 'S', 'એ', 'એફ', 'ડી', 'ના', 'વ્યાજ', 'દર', 'માં', '0', '25', 'ટકા', 'સુધી', 'નો']\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "\n",
        "tokens_cleaned_unigram = [token.replace('▁', '') for token in unigram_list if token not in punctuation_list and token not in matra ]\n",
        "ques_25_cleaned_unigram = [token.replace('▁', '') for token in ques_25_unigram if token not in punctuation_list ]\n",
        "\n",
        "# Count the frequency of each token\n",
        "token_freq = Counter(tokens_cleaned_unigram)\n",
        "\n",
        "unigram_token_freq_list = list(token_freq.items())\n",
        "# print(token_freq_list)\n",
        "unigram_sorted_token_freq_list = sorted(unigram_token_freq_list, key=lambda x: x[1], reverse=True)\n",
        "print(unigram_sorted_token_freq_list[:20])\n",
        "print(ques_25_cleaned_unigram)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDnAx-P0_a7u"
      },
      "source": [
        "# biagram of **Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad5N49lz_fnc",
        "outputId": "4fcde14f-e900-420f-e1e9-2171d2184683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('છે કે', 25014), ('છે અને', 20899), ('આવે છે', 17158), ('શકે છે', 15790), ('કરે છે', 15646), ('છે આ', 15489), ('કરવા માટે', 11541), ('થાય છે', 10614), ('છે તે', 10140), ('હોય છે', 10025), ('છે જે', 9899), ('શકો છો', 8813), ('છે પરંતુ', 7445), ('કારણ કે', 5948), ('રહી છે', 5855), ('હતું કે', 5718), ('કરવામાં આવે', 5512), ('કરી હતી', 5477), ('કરવામાં આવી', 5154), ('કેવી રીતે', 5000)]\n"
          ]
        }
      ],
      "source": [
        "bigram_token_list_unigram=[]\n",
        "bigram_token_list_unigram_sorted=[]\n",
        "bigram_token_list_unigram_sorted=get_bigramTokenizer_frequency(tokens_cleaned_unigram )\n",
        "print(bigram_token_list_unigram_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuItRgCTmxRg"
      },
      "source": [
        "# unigram and bigram of **character**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2HAkAvhmnoE"
      },
      "outputs": [],
      "source": [
        "processed_words_unigram = [] # list contain all the corrected unicode\n",
        "\n",
        "\n",
        "    # Process each word and store cleaned versions\n",
        "for word in tokens_cleaned_unigram:\n",
        "  cleaned_word = correct_unicode(word)  # Explain what this function does\n",
        "  processed_words_unigram.append(cleaned_word)\n",
        "        # print(f\"{word} => {cleaned_word}\")\n",
        "\n",
        "    # Increment the counter\n",
        "    # counter += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su5mNO2nm1qe",
        "outputId": "b7166207-d89d-4d57-e16f-84c3b44fe317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', ' મ્ ઈ', ' ઓ ગ્ અ સ્ ટ્ અ', '', ' ન્ આ', ' ર્ ઓ જ્ અ', ' આ દ્ ઇ વ્ આ સ્ ઈ', ' વ્ ઇ ક્ આ સ્ અ', ' સ્ અં ગ્ અ ઠ્ અ ન્ અ', ' દ્ વ્ આ ર્ આ']\n"
          ]
        }
      ],
      "source": [
        "N = 10\n",
        "result=[]\n",
        "result = processed_words_unigram[:N]\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBSqf5UYnCGp"
      },
      "source": [
        "**unigram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Zh2DLwXm-0y"
      },
      "outputs": [],
      "source": [
        "unigram_char_list_unigram=[]\n",
        "\n",
        "unigram_char_list_unigram_sorted=[]\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "for word in processed_words_unigram:\n",
        "\n",
        "  unigram_for_char(word, vyanjan,unigram_char_list_unigram) # unigram for character\n",
        "\n",
        "  # print(\" unigram characters \")\n",
        "\n",
        "unigram_char_list_unigram_sorted=sort_list_by_frequency(unigram_char_list_unigram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oeq7E8HZnKcp",
        "outputId": "171266cf-6036-4eaa-ad7d-d320d339f8bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ', 7699681), ('આ', 3597560), ('એ', 2441179), ('ર્', 2128526), ('ન્', 1734112), ('ઈ', 1506733), ('ક્', 1386555), ('મ્', 1324843), ('ત્', 1207724), ('વ્', 1149790), ('ઓ', 1147198), ('સ્', 976491), ('પ્', 867048), ('ઇ', 757982), ('ય્', 745130), ('લ્', 684911), ('ઉ', 654046), ('જ્', 585042), ('ટ્', 520557), ('હ્', 516880)]\n"
          ]
        }
      ],
      "source": [
        "print(unigram_char_list_unigram_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3RgDj5Znmzl"
      },
      "source": [
        "**bigram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R72vyimonoml",
        "outputId": "2851948e-85d2-4961-f11a-21ae1e49d580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર્અ', 1050220), ('અર', 800138), ('ક્અ', 675012), ('મ્આ', 571982), ('અન', 474041), ('મ્અ', 446722), ('સ્અ', 443649), ('પ્અ', 438990), ('ન્અ', 434633), ('આર', 415539), ('વ્આ', 398727), ('ત્અ', 380510), ('ન્એ', 368759), ('વ્અ', 352516), ('ન્આ', 334302), ('છ્એ', 322229), ('અત', 312870), ('ય્અ', 306558), ('અવ', 293257), ('અમ', 290588)]\n"
          ]
        }
      ],
      "source": [
        "bigram_char_list_unigram=[]\n",
        "\n",
        "bigram_char_list_unigram_sorted=[]\n",
        "\n",
        "from collections import Counter\n",
        "for word in processed_words_unigram:\n",
        "   bigram_for_char(word, vyanjan,bigram_char_list_unigram) # bigram for character\n",
        "bigram_char_list_unigram_sorted=sort_list_by_frequency(bigram_char_list_unigram)\n",
        "print(bigram_char_list_unigram_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf7lHQgcozU-"
      },
      "source": [
        "# unigram and bigram of **syllable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GozsjkYQo0ou"
      },
      "outputs": [],
      "source": [
        "unigram_syllables_list_unigram=[]\n",
        "unigram_syllabless=[]\n",
        "unigram_syllables_list_sorted_unigram=[]\n",
        "swapped_dict = {v: k for k, v in gujarati_dict.items()}\n",
        "\n",
        "# print(swapped_dict)\n",
        "# resullt = [' મ્ ઈ', ' ઓ ગ્ અ સ્ ટ્ અ', ' ન્ આ']\n",
        "spchar = '@'\n",
        "count =0\n",
        "for word in processed_words_unigram:\n",
        "\n",
        "  unigram_syllables(word,swar,vyanjan,swapped_dict,unigram_syllables_list_unigram,unigram_syllabless)\n",
        "  unigram_syllabless.append(spchar)\n",
        "\n",
        "\n",
        "\n",
        "unigram_syllables_list_sorted_unigram=sort_list_by_frequency(unigram_syllables_list_unigram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xfq1a6Uqq8B",
        "outputId": "ff7ae7b8-6cc9-41a6-b8ed-e20a06ad863e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર', 867602), ('ક', 646763), ('મા', 564727), ('ન', 419919), ('મ', 417827), ('પ', 409034), ('સ', 403761), ('વા', 368610), ('ને', 362675), ('અ', 354831), ('ત', 335471), ('ના', 332373), ('આ', 331134), ('છે', 321824), ('વ', 313431), ('લ', 263967), ('એ', 250862), ('જ', 237780), ('ની', 236844), ('તે', 211708)]\n"
          ]
        }
      ],
      "source": [
        "print(unigram_syllables_list_sorted_unigram[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEtA7EXuquRj",
        "outputId": "e1c1a99b-3cb3-4bdf-881c-eb0b152573aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ ને', 156376), ('ક ર', 97098), ('પ ર', 89565), ('મા ટે', 83880), ('એ ક', 70604), ('ર વા', 65827), ('પ ણ', 59595), ('ક રી', 55860), ('વા મા', 46448), ('સા થે', 45703), ('કા ર', 42922), ('તે મ', 42918), ('ત મા', 36253), ('સ મ', 34671), ('હ તી', 32761), ('ન થી', 30440), ('ઉ પ', 29942), ('આ વે', 28184), ('ર ણ', 26263), ('ત મે', 26135)]\n"
          ]
        }
      ],
      "source": [
        "bigram_syllables_list_unigram=[]\n",
        "bigram_syllables_list_sorted_unigram=[]\n",
        "bigram_syllables_list_sorted_unigram=get_bisyllable_frequency(unigram_syllabless,bigram_syllables_list_unigram)\n",
        "print(bigram_syllables_list_sorted_unigram[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWnmSzLkwU7A"
      },
      "source": [
        "# **IndicBERT max_length=1000**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n9bpppmE3_s"
      },
      "source": [
        "**download dependency**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Xo9uwuwwuTB",
        "outputId": "0af2342c-b80a-4cb6-81a4-2a78522ac326"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\asus\\anaconda3\\lib\\site-packages (4.32.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
            "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.9.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: sentencepiece in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.1.99)\n",
            "Requirement already satisfied: protobuf in c:\\users\\asus\\anaconda3\\lib\\site-packages (4.25.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install protobuf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azkGRiIDzPVi"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "from collections import Counter\n",
        "tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert',keep_accents=True)\n",
        "# model = AutoModel.from_pretrained(\"ai4bharat/indic-bert\")\n",
        "print('*** IndicBert ***')\n",
        "# sentence = \"લોકો બેંકોની બહાર ઊભાં રહી ગયાં હતાં\"\n",
        "# tokenized_input = tokenizer(sentence)\n",
        "\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/temp.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "# Tokenize a sentence\n",
        "with open('ques_25.txt', 'r', encoding='utf-8') as file:\n",
        "    text2 = file.read()\n",
        "tokens = tokenizer(text,max_length=1000,truncation=True)\n",
        "tokens2 = tokenizer(text2)\n",
        "indicBert_list=tokenizer.convert_ids_to_tokens(tokens['input_ids'])\n",
        "indicBert_list2=tokenizer.convert_ids_to_tokens(tokens2['input_ids'])\n",
        "# print(\"segmented input sentence \",tokenizer.convert_ids_to_tokens(tokens['input_ids']))\n",
        "\n",
        "indicBert_tokens_cleaned = [token.replace('▁', '') for token in indicBert_list if token not in punctuation_list and token not in matra ]\n",
        "indicBert_q25_list_cleaned = [token.replace('▁', '') for token in indicBert_list2 if token not in punctuation_list and token not in matra ]\n",
        "\n",
        "# Count the frequency of each token\n",
        "indicBert_token_freq = Counter(indicBert_tokens_cleaned)\n",
        "\n",
        "indicBert_token_freq_list = list(indicBert_token_freq.items())\n",
        "# print(token_freq_list)\n",
        "indicBert_sorted_token_freq_list = sorted(indicBert_token_freq_list, key=lambda x: x[1], reverse=True)\n",
        "print(indicBert_sorted_token_freq_list[:20])\n",
        "print(indicBert_q25_list_cleaned)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej91xJXeyJki"
      },
      "source": [
        "# biagram of **Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkF8un2O_s50",
        "outputId": "a086b5ea-f327-40ce-e03b-8804def5e436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('છે કે', 4), ('કરે છે', 2), ('બંધ ના', 2), ('રહી છે', 2), ('આવી છે', 2), ('ગ્લાસ ફ', 2), ('ફ ાયબર', 2), ('છે આ', 2), ('છે તે', 2), ('છે એ', 2), ('છે અને', 2), ('પદ ાનુ', 2), ('ાનુ ક્રમ', 2), ('કર્યો છે', 2), ('કરી શકે', 2), ('શકે છે', 2), ('હોય છે', 2), ('[CLS] ૯', 1), ('૯ મી', 1), ('મી ઓગસ્ટ', 1)]\n"
          ]
        }
      ],
      "source": [
        "bigram_token_indicbert_1000=[]\n",
        "bigram_token_indicbert_1000_sorted=[]\n",
        "bigram_token_indicbert_1000_sorted=get_bigramTokenizer_frequency(indicBert_tokens_cleaned )\n",
        "print(bigram_token_indicbert_1000_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFcIqzJcyKcM"
      },
      "source": [
        "# unigram and bigram of **character**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aImSIeuWyVbX"
      },
      "outputs": [],
      "source": [
        "processed_words_indicbert_1000 = [] # list contain all the corrected unicode\n",
        "\n",
        "\n",
        "    # Process each word and store cleaned versions\n",
        "for word in indicBert_tokens_cleaned:\n",
        "  cleaned_word = correct_unicode(word)  # Explain what this function does\n",
        "  processed_words_indicbert_1000.append(cleaned_word)\n",
        "        # print(f\"{word} => {cleaned_word}\")\n",
        "\n",
        "    # Increment the counter\n",
        "    # counter += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CSo7wYhyijW",
        "outputId": "32a8175e-48b3-4575-ed4c-1072634a53ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '', ' મ્ ઈ', ' ઓ ગ્ અ સ્ ટ્ અ', '', ' ન્ આ', ' ર્ ઓ જ્ અ', ' આ દ્ ઇ વ્ આ સ્ ઈ', ' વ્ ઇ ક્ આ સ્ અ', ' સ્ ગ્ અ ઠ્ અ ન્ અ']\n"
          ]
        }
      ],
      "source": [
        "N = 10\n",
        "result=[]\n",
        "result = processed_words_indicbert_1000[:N]\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt-lyi0jyxXA"
      },
      "source": [
        "**unigram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcj6iu8_yzAk"
      },
      "outputs": [],
      "source": [
        "unigram_char_list_indicbert_1000=[]\n",
        "\n",
        "unigram_char_list_indicbert_1000_sorted=[]\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "for word in processed_words_indicbert_1000:\n",
        "\n",
        "  unigram_for_char(word, vyanjan,unigram_char_list_indicbert_1000) # unigram for character\n",
        "\n",
        "  # print(\" unigram characters \")\n",
        "\n",
        "unigram_char_list_indicbert_1000_sorted=sort_list_by_frequency(unigram_char_list_indicbert_1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyXalO0iy6F4",
        "outputId": "ce64a00c-7956-4bc1-8983-cf3131ff6bcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ', 819), ('આ', 379), ('એ', 258), ('ર્', 226), ('ન્', 181), ('ઈ', 164), ('ક્', 150), ('મ્', 142), ('ત્', 134), ('ઓ', 125), ('વ્', 122), ('સ્', 104), ('પ્', 88), ('ઇ', 83), ('ય્', 69), ('જ્', 66), ('ઉ', 65), ('લ્', 65), ('બ્', 56), ('દ્', 52)]\n"
          ]
        }
      ],
      "source": [
        "print(unigram_char_list_indicbert_1000_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWmby9uoy-VF"
      },
      "source": [
        "**bigram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLSanxITy9R1",
        "outputId": "edefef53-7350-4d39-b9f6-9925df61fed3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર્અ', 124), ('અર', 85), ('ક્અ', 65), ('અન', 63), ('મ્આ', 57), ('ન્અ', 54), ('પ્અ', 53), ('વ્અ', 48), ('ત્અ', 48), ('મ્અ', 47), ('આર', 45), ('વ્આ', 42), ('અત', 40), ('છ્એ', 40), ('સ્અ', 39), ('અવ', 37), ('ન્એ', 37), ('અમ', 37), ('અણ', 29), ('લ્અ', 29)]\n"
          ]
        }
      ],
      "source": [
        "bigram_char_list_indicbert_1000=[]\n",
        "\n",
        "bigram_char_list_indicbert_1000_sorted=[]\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "for word in processed_words_indicbert_1000:\n",
        "   bigram_for_char(word, vyanjan,bigram_char_list_indicbert_1000) # bigram for character\n",
        "bigram_char_list_indicbert_1000_sorted=sort_list_by_frequency(bigram_char_list_indicbert_1000)\n",
        "\n",
        "print(bigram_char_list_indicbert_1000_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxEjcHrmyNE0"
      },
      "source": [
        "# unigram and bigram of **syllable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOBqM1A0zRXv"
      },
      "outputs": [],
      "source": [
        "unigram_syllables_list_indicbert_1000=[]\n",
        "unigram_syllabless=[]\n",
        "unigram_syllables_list_sorted_indicbert_1000=[]\n",
        "swapped_dict = {v: k for k, v in gujarati_dict.items()}\n",
        "\n",
        "# print(swapped_dict)\n",
        "# resullt = [' મ્ ઈ', ' ઓ ગ્ અ સ્ ટ્ અ', ' ન્ આ']\n",
        "spchar = '@'\n",
        "count =0\n",
        "for word in processed_words_indicbert_1000:\n",
        "\n",
        "  unigram_syllables(word,swar,vyanjan,swapped_dict,unigram_syllables_list_indicbert_1000,unigram_syllabless)\n",
        "  unigram_syllabless.append(spchar)\n",
        "\n",
        "\n",
        "\n",
        "unigram_syllables_list_sorted_indicbert_1000=sort_list_by_frequency(unigram_syllables_list_indicbert_1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToBD_z46z1Ui",
        "outputId": "7159c291-d2bd-41ee-8e2e-da3482fe9d8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર', 90), ('ક', 65), ('ન', 54), ('મા', 54), ('પ', 50), ('આ', 46), ('મ', 45), ('વ', 44), ('ત', 43), ('છે', 40), ('વા', 38), ('સ', 37), ('ને', 37), ('અ', 35), ('એ', 32), ('લ', 29), ('ના', 27), ('બ', 26), ('ગ', 24), ('તે', 24)]\n"
          ]
        }
      ],
      "source": [
        "print(unigram_syllables_list_sorted_indicbert_1000[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUF0WBsRz6cY",
        "outputId": "d731bb9d-5f6f-4c36-a52e-88f79522135a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ ને', 13), ('મા ટે', 9), ('ક ર', 7), ('ત મા', 7), ('સ મ', 6), ('આ પ', 6), ('એ ક', 6), ('તે મ', 6), ('ર વા', 5), ('પ ર', 5), ('સા થે', 5), ('ગ ર', 5), ('દ ર', 5), ('તે ઓ', 5), ('ર સ', 5), ('પ ણ', 5), ('વા સી', 4), ('વા મા', 4), ('ત ર', 4), ('ટે લ', 4)]\n"
          ]
        }
      ],
      "source": [
        "bigram_syllables_list_indicbert_1000=[]\n",
        "bigram_syllables_list_sorted_indicbert_1000=[]\n",
        "bigram_syllables_list_sorted_indicbert_1000=get_bisyllable_frequency(unigram_syllabless,bigram_syllables_list_indicbert_1000)\n",
        "print(bigram_syllables_list_sorted_indicbert_1000[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rxCDZmNCrXR"
      },
      "source": [
        "# **IndicBERT max_length=2000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "losjGadXC1-C",
        "outputId": "c7752824-8c21-4f0f-a487-a28386e00ffa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** IndicBert ***\n",
            "[('છે', 43), ('ની', 17), ('અને', 15), ('ને', 12), ('માટે', 11), ('નો', 10), ('', 9), ('માં', 9), ('સાથે', 9), ('ના', 8), ('એ', 8), ('જે', 8), ('જ', 7), ('આ', 7), ('કે', 7), ('પણ', 7), ('થી', 6), ('તા', 6), ('તે', 6), ('એક', 6)]\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "print('*** IndicBert ***')\n",
        "# sentence = \"લોકો બેંકોની બહાર ઊભાં રહી ગયાં હતાં\"\n",
        "# tokenized_input = tokenizer(sentence)\n",
        "\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/temp.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "# Tokenize a sentence\n",
        "\n",
        "tokens = tokenizer(text,max_length=2000,truncation=True)\n",
        "\n",
        "indicBert_list_2000=tokenizer.convert_ids_to_tokens(tokens['input_ids'])\n",
        "# print(\"segmented input sentence \",tokenizer.convert_ids_to_tokens(tokens['input_ids']))\n",
        "\n",
        "indicBert_tokens_cleaned_2000 = [token.replace('▁', '') for token in indicBert_list_2000 if token not in punctuation_list and token not in matra ]\n",
        "\n",
        "# Count the frequency of each token\n",
        "indicBert_token_freq_2000 = Counter(indicBert_tokens_cleaned_2000)\n",
        "\n",
        "indicBert_token_freq_list_2000 = list(indicBert_token_freq_2000.items())\n",
        "# print(token_freq_list)\n",
        "indicBert_sorted_token_freq_list_2000 = sorted(indicBert_token_freq_list_2000, key=lambda x: x[1], reverse=True)\n",
        "print(indicBert_sorted_token_freq_list_2000[:20])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEVlfvDqDs_v"
      },
      "source": [
        "# biagram of **Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M41S9BEqDojh",
        "outputId": "78b09bca-7172-4f29-a2e8-22415543b625"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('છે કે', 4), ('હોય છે', 3), ('કરે છે', 2), ('બંધ ના', 2), ('રહી છે', 2), ('આવી છે', 2), ('ગ્લાસ ફ', 2), ('ફ ાયબર', 2), ('છે આ', 2), ('છે તે', 2), ('છે એ', 2), ('છે અને', 2), ('પદ ાનુ', 2), ('ાનુ ક્રમ', 2), ('કર્યો છે', 2), ('ઉપયોગ કરી', 2), ('કરી શકે', 2), ('શકે છે', 2), ('આધ ેડ', 2), ('[CLS] ૯', 1)]\n"
          ]
        }
      ],
      "source": [
        "bigram_token_indicbert_2000=[]\n",
        "bigram_token_indicbert_2000_sorted=[]\n",
        "bigram_token_indicbert_2000_sorted=get_bigramTokenizer_frequency(indicBert_tokens_cleaned_2000 )\n",
        "print(bigram_token_indicbert_2000_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeYDof2MD-v0"
      },
      "source": [
        "# unigram and bigram of **character**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQIoIcQ4ENap"
      },
      "outputs": [],
      "source": [
        "processed_words_indicbert_2000 = [] # list contain all the corrected unicode\n",
        "\n",
        "\n",
        "    # Process each word and store cleaned versions\n",
        "for word in indicBert_tokens_cleaned_2000:\n",
        "  cleaned_word = correct_unicode(word)  # Explain what this function does\n",
        "  processed_words_indicbert_2000.append(cleaned_word)\n",
        "        # print(f\"{word} => {cleaned_word}\")\n",
        "\n",
        "    # Increment the counter\n",
        "    # counter += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9w35Hc2EasK",
        "outputId": "cb095773-c0ed-4441-eae8-8d8077ddfc17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '', ' મ્ ઈ', ' ઓ ગ્ અ સ્ ટ્ અ', '', ' ન્ આ', ' ર્ ઓ જ્ અ', ' આ દ્ ઇ વ્ આ સ્ ઈ', ' વ્ ઇ ક્ આ સ્ અ', ' સ્ અં ગ્ અ ઠ્ અ ન્ અ']\n"
          ]
        }
      ],
      "source": [
        "N = 10\n",
        "result=[]\n",
        "result = processed_words_indicbert_2000[:N]\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96zGXStFEw7u"
      },
      "source": [
        "**unigram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ME4KwXOE2hV"
      },
      "outputs": [],
      "source": [
        "unigram_char_list_indicbert_2000=[]\n",
        "\n",
        "unigram_char_list_indicbert_2000_sorted=[]\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "for word in processed_words_indicbert_2000:\n",
        "\n",
        "  unigram_for_char(word, vyanjan,unigram_char_list_indicbert_2000) # unigram for character\n",
        "\n",
        "  # print(\" unigram characters \")\n",
        "\n",
        "unigram_char_list_indicbert_2000_sorted=sort_list_by_frequency(unigram_char_list_indicbert_2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8IoJho_FSOx",
        "outputId": "b613dc88-c88e-4f33-8e8b-f10e1b1ee593"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ', 1014), ('આ', 464), ('એ', 294), ('ર્', 272), ('ન્', 216), ('ઈ', 201), ('ક્', 178), ('મ્', 168), ('ત્', 158), ('ઓ', 155), ('વ્', 141), ('સ્', 133), ('પ્', 104), ('ઇ', 95), ('લ્', 86), ('ય્', 84), ('જ્', 83), ('ઉ', 75), ('દ્', 62), ('ગ્', 59)]\n"
          ]
        }
      ],
      "source": [
        "print(unigram_char_list_indicbert_2000_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev-MG8TIEz5P"
      },
      "source": [
        "**bigram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYFEZQRUFUsy",
        "outputId": "9ce86319-f9c7-454d-c62c-d98d229199e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર્અ', 156), ('અર', 102), ('ક્અ', 79), ('અન', 72), ('મ્આ', 67), ('પ્અ', 64), ('સ્અ', 63), ('ન્અ', 62), ('આર', 60), ('વ્અ', 57), ('મ્અ', 56), ('ત્અ', 55), ('વ્આ', 51), ('અત', 49), ('અવ', 45), ('અમ', 45), ('છ્એ', 44), ('ન્એ', 42), ('અક', 35), ('બ્અ', 34)]\n"
          ]
        }
      ],
      "source": [
        "bigram_char_list_indicbert_2000=[]\n",
        "\n",
        "bigram_char_list_indicbert_2000_sorted=[]\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "for word in processed_words_indicbert_2000:\n",
        "   bigram_for_char(word, vyanjan,bigram_char_list_indicbert_2000) # bigram for character\n",
        "bigram_char_list_indicbert_2000_sorted=sort_list_by_frequency(bigram_char_list_indicbert_2000)\n",
        "\n",
        "print(bigram_char_list_indicbert_2000_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6j-Ej28Fd5m"
      },
      "source": [
        "# unigram and bigram of **syllable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FY_0AkQFjvy"
      },
      "outputs": [],
      "source": [
        "unigram_syllables_list_indicbert_2000=[]\n",
        "unigram_syllabless=[]\n",
        "unigram_syllables_list_sorted_indicbert_2000=[]\n",
        "swapped_dict = {v: k for k, v in gujarati_dict.items()}\n",
        "\n",
        "# print(swapped_dict)\n",
        "# resullt = [' મ્ ઈ', ' ઓ ગ્ અ સ્ ટ્ અ', ' ન્ આ']\n",
        "spchar = '@'\n",
        "count =0\n",
        "for word in processed_words_indicbert_2000:\n",
        "\n",
        "  unigram_syllables(word,swar,vyanjan,swapped_dict,unigram_syllables_list_indicbert_2000,unigram_syllabless)\n",
        "  unigram_syllabless.append(spchar)\n",
        "\n",
        "\n",
        "\n",
        "unigram_syllables_list_sorted_indicbert_2000=sort_list_by_frequency(unigram_syllables_list_indicbert_2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYisZ8abF7EF",
        "outputId": "9cdc3ec9-8778-4b9c-c4d0-900c55637feb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર', 122), ('ક', 79), ('મા', 64), ('ન', 62), ('પ', 61), ('સ', 57), ('વ', 53), ('મ', 53), ('આ', 52), ('ત', 50), ('વા', 47), ('છે', 44), ('અ', 42), ('ને', 42), ('એ', 35), ('લ', 34), ('ના', 33), ('બ', 33), ('જ', 31), ('ની', 30)]\n"
          ]
        }
      ],
      "source": [
        "print(unigram_syllables_list_sorted_indicbert_2000[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgUh6uyQF-mH",
        "outputId": "2b4014c9-37a8-4a9e-bb3d-866f078c8479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ ને', 16), ('મા ટે', 11), ('ક ર', 10), ('સા થે', 9), ('પ ર', 8), ('ત મા', 8), ('આ પ', 7), ('ગ ર', 7), ('પ ણ', 7), ('ત ર', 6), ('સ મ', 6), ('દ ર', 6), ('એ ક', 6), ('તે મ', 6), ('ર વા', 5), ('તે ઓ', 5), ('રા જ', 5), ('ર સ', 5), ('ર ણ', 5), ('કા ર', 5)]\n"
          ]
        }
      ],
      "source": [
        "bigram_syllables_list_indicbert_2000=[]\n",
        "bigram_syllables_list_sorted_indicbert_2000=[]\n",
        "bigram_syllables_list_sorted_indicbert_2000=get_bisyllable_frequency(unigram_syllabless,bigram_syllables_list_indicbert_2000)\n",
        "print(bigram_syllables_list_sorted_indicbert_2000[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t5V5S--1yCP"
      },
      "source": [
        "# **mBERT max_length=1000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYi62_ia1xSo"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, TFBertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased',max_length=1000,do_lower_case=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZudDnF7D_Pp",
        "outputId": "e61671d2-f5c6-4ca9-c918-2513c25d2e3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** mBert ***\n"
          ]
        }
      ],
      "source": [
        "print('*** mBert ***')\n",
        "with open('gu_100.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "# Tokenize a sentence\n",
        "with open('ques_25.txt', 'r', encoding='utf-8') as file:\n",
        "    text2 = file.read()\n",
        "# sentence = \"તમારું નામ શું છે?\"\n",
        "mbert_tokens = tokenizer.tokenize(text)\n",
        "mbert_ques_25_tokens = tokenizer.tokenize(text2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsmDFDVC1tK3",
        "outputId": "9d5557a9-ed4a-4ecf-f1ef-e84367fd21e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર', 726633), ('સ', 704144), ('મ', 683027), ('ક', 649642), ('પ', 624156), ('ા', 597880), ('ો', 580944), ('ે', 498472), ('િ', 455953), ('વ', 442840), ('ન', 440317), ('જ', 423183), ('લ', 383647), ('ી', 333884), ('ત', 333560), ('બ', 322287), ('છે', 321025), ('દ', 307605), ('્', 294539), ('હ', 286944)]\n",
            "['ડ', 'િ', 'સ', '્', 'પ', '્', 'લે', 'પર', 'પણ', 'ય', 'ાં', 'ત', '્ર', 'િક', 'ન', 'ુ', 'ક', 'સ', 'ાન', 'ક', 'ો', 'ર', '્ન', 'િ', 'ંગ', 'ગ', '્', 'લા', 'સ', 'થી', 'એક', 'ખ', 'ાસ', 'ર', 'ક', '્', 'ષણ', 'ાત', '્મ', 'ક', 'સ', '્ત', 'ર', 'છે', '2017', 'ઇ', '1270', 'પ', 'ા', 'ક', 'િ', 'સ', '્ત', 'ાન', 'ના', 'પ', 'ી', 'એ', 'મ', 'ઈ', 'મ', 'રા', 'ન', 'ખ', 'ાન', 'ની', 'અ', 'ધ', '્ય', 'ક', '્', 'ષ', 'તા', 'માં', 'આ', 'બે', 'ઠ', 'ક', 'બ', 'ો', 'લા', 'વવામાં', 'આવી', 'છે', 'આવી', 'ઘ', 'ટ', 'ના', 'માં', 'છે', 'ત', 'ર', 'પ', 'િ', 'ં', 'ડી', 'ક', 'ર', 'ના', 'ર', 'વ', '્ય', 'ક', '્તિ', 'મ', 'ો', 'ટ', 'ે', 'ભ', 'ાગ', 'ે', 'પર', 'િ', 'ચ', 'િત', 'અથવા', 'તો', 'સ', 'ં', 'બ', 'ં', 'ધી', 'હોય', 'છે', 'એ', 'વ', 'ાત', 'વ', 'ધ', 'ારે', 'આ', 'ઘ', 'ાત', 'જ', 'ન', 'ક', 'હોય', 'છે', 'આ', 'પ', 'તા', 'વ', 'ટ', 'ની', 'આ', 'ંત', 'ર', 'મ', 'ાળ', 'ખ', 'ા', 'ખ', 'ૂ', 'બ', 'સ', 'ારી', 'રીતે', 'વ', 'િક', 'સ', 'િત', 'નથી', 'આ', 'ર', 'ક', 'મ', 'આ', 'શ', 'રે', 'છે', 'અ', 'મ', 'ે', 'આ', 'મ', 'ામ', 'લે', 'બ', 'હ', 'ાર', 'નાં', 'વ', '્ય', 'ક', '્તિ', 'નાં', 'ક', 'ો', 'ઇ', 'પણ', 'દ', 'ા', 'વા', 'ને', 'સ', 'ં', 'પ', 'ૂર', '્ણ', 'રીતે', 'ફ', 'ગ', 'ા', 'વી', 'એ', 'છ', 'ી', 'એ', 'આ', 'ક', 'િ', 'સ', '્સ', 'ા', 'ઓ', 'માં', 'એ', 'ન્ટ', 'િ', 'બ', 'ાય', 'ો', 'ટ', 'િક', '્સ', 'સાથે', 'સ', 'ાર', 'વાર', 'જ', 'ર', 'ૂર', 'છે', 'ત', 'મ', 'ારી', 'ર', 'ા', 'શ', 'િ', 'ના', 'લોકો', 'એ', 'હ', 'ા', 'લ', 'દ', 'ુ', 'ર', '્', 'ઘ', 'ટ', 'ના', 'ઓ', 'થી', 'સ', 'ા', 'વ', 'ધ', 'ાન', 'ર', 'હે', 'વાની', 'જ', 'ર', 'ૂર', 'છે', 'આ', 'બ', 'ા', 'બ', 'ત', 'છે', 'ત', '્યા', 'ર', 'બ', 'ા', 'દ', 'સ', 'ી', 'બ', 'ી', 'આ', 'ઇ', 'અને', 'ઇ', 'ડી', 'એ', 'પ', 'ૂર', 'ક', 'ચ', 'ાર', '્', 'જ', 'શ', 'ી', 'ટ', 'દ', 'ા', 'ખ', 'લ', 'કરી', 'હતી', 'ઈ', 'ન', '્ડ', 'િયન', 'આ', 'ઈ', 'ડ', 'લ', '11', 'ના', 'આ', 'ગ', 'ામ', 'ી', 'એ', 'પ', 'િ', 'સ', 'ો', 'ડ', 'માં', 'ઉ', 'દ', 'િત', 'ના', 'રા', 'ય', 'ણ', 'અને', 'અ', 'લ', 'કા', 'ય', 'ા', 'જ', '્', 'ઞ', 'િક', 'મ', 'હે', 'માન', 'બ', 'ન', 'શે', 'જ્યારે', 'ક', '્', 'લે', 'ર', 'િ', 'સ', 'અને', 'મ', 'િત', '્સ', 'ુ', 'ઇ', 'નો', 'સ', 'માન', 'હ', 'િ', 'સ', '્સ', 'ો', 'હતો', 'આ', 'થી', 'ઋ', 'ષ', 'િક', 'ેશ', 'ન', 'ગર', 'માં', 'વ', 'િ', 'ર', 'ભ', 'દ', '્ર', 'બ', 'ં', 'ધ', 'ના', 'દ', '્વ', 'ાર', 'પ', 'ાસ', 'ે', 'તે', 'ફ', 'સ', 'ા', 'ઈ', 'ગ', 'યો', 'હતો', 'ઉ', 'રી', 'હ', 'ુ', 'મ', 'લા', 'પછી', 'ભારતીય', 'સ', 'ે', 'ના', 'ત', 'ર', 'ફ', 'થી', 'સ', 'ર', '્', 'જ', 'િક', 'લ', 'સ', '્ટ', '્ર', 'ા', 'ઇ', 'ક', 'કરવામાં', 'આવી', 'આ', 'ખ', 'ૂ', 'બ', 'જ', 'ખ', 'ત', 'ર', 'ના', 'ક', 'મ', 'િ', 'શન', 'ને', 'સ', 'ફ', 'ળ', 'તા', 'પ', 'ૂર્વ', 'ક', 'પ', 'ાર', 'પ', 'ા', 'ડ', 'વા', 'નો', 'શ', '્ર', 'ે', 'ય', 'જ', 'ાય', 'છે', 'ભારત', 'ના', 'ર', 'ા', 'ષ', '્ટ', '્રીય', 'સ', 'ુ', 'ર', 'ક', '્', 'ષ', 'ા', 'સ', 'લા', 'હ', 'કાર', 'અ', 'જી', 'ત', 'ડ', 'ોવા', 'લ', 'વ', '્યા', 'પ', 'ક', 'દ', 'ર', 'િયા', 'ક', 'િ', 'ના', 'રો', 'જે', 'ના', 'માટે', 'સ', 'ર', 'કાર', 'ે', 'ઘ', 'ણી', 'બ', 'ધી', 'ય', 'ો', 'જ', 'ના', 'ઓ', 'પણ', 'ઘ', 'ડી', 'છે', 'કે', 'ખ', 'ે', 'ડ', 'ૂ', 'તો', 'ને', 'થ', 'ો', 'ડા', 'ઘ', 'ણા', 'અ', 'ં', 'શે', 'પ', 'ો', 'તા', 'ની', 'ત', 'ક', 'લી', 'ફ', 'માં', 'ર', 'ા', 'હ', 'ત', 'મ', 'ળી', 'ર', 'હે', 'સ', '્', 'પે', 'ન', '્સ', 'ર', 'ી', 'સ', 'શ', 'િ', 'ષ', '્ય', 'વ', 'ૃ', 'ત', '્તિ', 'જ', 'ો', 'ત', 'મ', 'ે', 'સ', 'લ', '્', 'ફ', 'ર', 'માં', 'થી', 'સ', 'ામ', 'ય', 'િક', 'ટ', 'ે', 'બ', 'લ', 'ને', 'ની', 'ચ', 'ે', 'ખ', 'સ', 'ે', 'ડ', 'ો', 'તેમણે', 'ક', 'રો', 'ડ', 'ો', 'પ', 'તિ', 'નો', 'દ', 'ર', 'જ', '્', 'જ', 'ો', 'પ', '્ર', 'ાપ્ત', 'કર્યો', 'છે', 'ક', 'ાર', 'ણ', 'કે', 'તેઓ', 'એ', 'સ', 'ત', 'ત', 'ઘ', 'ણી', 'સ', 'ં', 'પ', 'ત', '્તિ', 'ન', 'િ', 'ર', '્મ', 'ાણ', 'ની', 'વ', '્ય', 'ૂ', 'હ', 'ર', 'ચ', 'ના', 'ઓ', 'નો', 'ઉપયોગ', 'કર્યો', 'છે', 'કે', 'જેમાં', 'થી', 'ક', 'ોઈ', 'પણ', 'ઉપયોગ', 'કરી', 'શકે', 'છે', 'આ', 'જ', 'ે', 'થી', 'શ', 'ર', 'ૂ', 'અ', 'હીં', 'આ', 'ગ', 'ામ', 'ી', 'બ', 'ારો', 'માં', 'થી', 'મ', 'િ', 'લ', 'િયન', 'ે', 'ર', 'ના', 'બ', 'ાર', 'લ', 'ક', '્', 'ષણ', 'ો', 'છે', 'પ', 'ટ', 'પ', 'ટ', 'તી', 'પ', 'ા', 'પ', 'ણ', 'ો', 'લોકો', 'ક', 'ા', 'દ', 'વ', 'માં', 'ન', 'હ', 'ોઈ', 'શકે', 'આ', 'લ', 'ે', 'ખ', 'માં', 'અ', 'મ', 'ે', 'ત', 'મ', 'ને', 'ક', 'હી', 'શ', 'ું', 'કે', 'સ', '્વ', 'િ', 'મ', 'િ', 'ંગ', 'ને', 'વધુ', 'ર', 'સ', 'પ', '્ર', 'દ', 'વધુ', 'ખ', 'ાસ', 'બ', 'ાં', 'ધ', 'કા', 'મ', 'મ', 'િ', 'શ', '્રણ', 'વ', 'ા', 'પ', 'રી', 'ને', 'મ', 'ાળ', 'ભ', 'ર', 'વા', 'એક', 'મ', 'ો', 'ટી', 'સ', 'ો', 'દ', 'ો', 'નથી', 'મ', 'ાર', '્ક', 'ે', 'ટ', 'વ', 'ેલ', '્ય', 'ુ', 'ની', 'દ', '્ર', 'ષ', '્ટ', 'િ', 'એ', 'ક', 'ો', 'ટ', 'ક', 'મ', 'હ', 'િ', 'ન', '્', 'દ', '્ર', 'ા', 'બે', 'ં', 'ક', 'એ', 'ચ', 'ડી', 'એ', 'ફ', 'સી', 'બાદ', 'બ', 'ી', 'જા', 'ન', 'ં', 'બર', 'ની', 'SB', 'I', 'એ', 'એ', 'ફ', 'ડી', 'ના', 'વ', '્યા', 'જ', 'દ', 'ર', 'માં', '25', 'ટ', 'કા', 'સુધી', 'નો']\n"
          ]
        }
      ],
      "source": [
        "# print(mbert_tokens[:20])\n",
        "from collections import Counter\n",
        "mBert_tokens_cleaned = [token.replace('#', '') for token in mbert_tokens if token not in punctuation_list ]\n",
        "mbert_ques_25_tokens_cleaned = [token.replace('#', '') for token in mbert_ques_25_tokens if token not in punctuation_list]\n",
        "\n",
        "# Count the frequency of each token\n",
        "mBert_token_freq = Counter(mBert_tokens_cleaned)\n",
        "\n",
        "mBert_token_freq_list = list(mBert_token_freq.items())\n",
        "# print(token_freq_list)\n",
        "mBert_sorted_token_freq_list = sorted(mBert_token_freq_list, key=lambda x: x[1], reverse=True)\n",
        "print(mBert_sorted_token_freq_list[:20])\n",
        "print(mbert_ques_25_tokens_cleaned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNkDQcICAA2N"
      },
      "source": [
        "# biagram of **Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5a7FvQ1AEHL",
        "outputId": "32a77e21-1725-453d-9177-dec16a7098af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('પ ્ર', 109266), ('વ િ', 95872), ('મ ે', 87313), ('ત મ', 68866), ('ર ્', 54493), ('સ ં', 51370), ('સ મ', 50033), ('સ ્', 49783), ('પ ો', 49127), ('ક ્', 47070), ('્ થ', 46468), ('ન િ', 44957), ('ક ર', 44654), ('જ ો', 44371), ('ર ા', 42642), ('મ ો', 42427), ('સ ર', 41479), ('પ ા', 41361), ('ા જ', 40165), ('મ ા', 38873)]\n"
          ]
        }
      ],
      "source": [
        "bigram_token_mbert_1000=[]\n",
        "bigram_token_mbert_1000_sorted=[]\n",
        "bigram_token_mbert_1000_sorted=get_bigramTokenizer_frequency(mBert_tokens_cleaned)\n",
        "\n",
        "print(bigram_token_mbert_1000_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L_gdVQVrxns"
      },
      "source": [
        "# unigram and bigram of **character**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjoOLFLOr4Cw"
      },
      "outputs": [],
      "source": [
        "processed_words_mbert_1000 = [] # list contain all the corrected unicode\n",
        "\n",
        "\n",
        "    # Process each word and store cleaned versions\n",
        "for word in mBert_tokens_cleaned:\n",
        "  cleaned_word = correct_unicode(word)  # Explain what this function does\n",
        "  processed_words_mbert_1000.append(cleaned_word)\n",
        "        # print(f\"{word} => {cleaned_word}\")\n",
        "\n",
        "    # Increment the counter\n",
        "    # counter += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nEik1LBsWVz",
        "outputId": "175e4979-17f3-4a0f-e4a8-b65352b067f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', ' મ્ ઈ', ' ઓ', ' ગ્ અ', ' સ્ ટ્ અ', '', '', '', '', ' ન્ આ']\n"
          ]
        }
      ],
      "source": [
        "N = 10\n",
        "result=[]\n",
        "result = processed_words_mbert_1000[:N]\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkTR7CJ9shVs"
      },
      "source": [
        "**unigram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLNSKMTxsi-_"
      },
      "outputs": [],
      "source": [
        "unigram_char_list_mbert_1000=[]\n",
        "\n",
        "unigram_char_list_mbert_1000_sorted=[]\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "for word in processed_words_mbert_1000:\n",
        "\n",
        "  unigram_for_char(word, vyanjan,unigram_char_list_mbert_1000) # unigram for character\n",
        "\n",
        "  # print(\" unigram characters \")\n",
        "\n",
        "unigram_char_list_mbert_1000_sorted=sort_list_by_frequency(unigram_char_list_mbert_1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgMuIVjKssX-",
        "outputId": "b9b41e0c-fab4-41b5-bf2c-92736a98f1bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ', 12713652), ('આ', 2357804), ('ર્', 2128340), ('એ', 1942445), ('ન્', 1733976), ('ક્', 1386470), ('મ્', 1324753), ('ઈ', 1255491), ('ત્', 1207677), ('વ્', 1149704), ('સ્', 976418), ('પ્', 867004), ('ય્', 745072), ('લ્', 684878), ('ઓ', 592856), ('જ્', 584943), ('ટ્', 520511), ('હ્', 516857), ('દ્', 427465), ('છ્', 412191)]\n"
          ]
        }
      ],
      "source": [
        "print(unigram_char_list_mbert_1000_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm_UR5wEszpX"
      },
      "source": [
        "**bigram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-ag0HCfs2Yp",
        "outputId": "ac52e5d6-79b5-42f9-a9cb-4de555e4617a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર્અ', 1609936), ('ક્અ', 1030111), ('મ્અ', 869185), ('સ્અ', 852688), ('પ્અ', 810258), ('ન્અ', 628773), ('વ્અ', 594341), ('ત્અ', 590295), ('જ્અ', 434663), ('લ્અ', 423574), ('મ્આ', 413067), ('ટ્અ', 400094), ('ય્અ', 398812), ('ગ્અ', 384654), ('હ્અ', 384602), ('અર', 367383), ('ન્એ', 361896), ('વ્આ', 345026), ('બ્અ', 337054), ('દ્અ', 325436)]\n"
          ]
        }
      ],
      "source": [
        "bigram_char_list_mbert_1000=[]\n",
        "\n",
        "bigram_char_list_mbert_1000_sorted=[]\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "for word in processed_words_mbert_1000:\n",
        "   bigram_for_char(word, vyanjan,bigram_char_list_mbert_1000) # bigram for character\n",
        "bigram_char_list_mbert_1000_sorted=sort_list_by_frequency(bigram_char_list_mbert_1000)\n",
        "\n",
        "print(bigram_char_list_mbert_1000_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdvCgGE4tBj8"
      },
      "source": [
        "# unigram and bigram of **syllable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpdzC-tftDEP"
      },
      "outputs": [],
      "source": [
        "unigram_syllables_list_mbert_1000=[]\n",
        "unigram_syllabless=[]\n",
        "unigram_syllables_list_sorted_mbert_1000=[]\n",
        "swapped_dict = {v: k for k, v in gujarati_dict.items()}\n",
        "\n",
        "# print(swapped_dict)\n",
        "# resullt = [' મ્ ઈ', ' ઓ ગ્ અ સ્ ટ્ અ', ' ન્ આ']\n",
        "spchar = '@'\n",
        "count =0\n",
        "for word in processed_words_mbert_1000:\n",
        "\n",
        "  unigram_syllables(word,swar,vyanjan,swapped_dict,unigram_syllables_list_mbert_1000,unigram_syllabless)\n",
        "  unigram_syllabless.append(spchar)\n",
        "\n",
        "\n",
        "\n",
        "unigram_syllables_list_sorted_mbert_1000=sort_list_by_frequency(unigram_syllables_list_mbert_1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtoS-GkttdAX",
        "outputId": "9cbc9ded-cf01-4db1-a2ee-3e2894e63418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર', 1585387), ('ક', 1030111), ('મ', 869185), ('સ', 852688), ('પ', 810258), ('ન', 628773), ('વ', 588452), ('ત', 584201), ('જ', 434663), ('લ', 423574), ('મા', 413067), ('ગ', 384654), ('હ', 384602), ('ય', 370055), ('ને', 361896), ('અ', 354822), ('ટ', 346219), ('બ', 333300), ('આ', 331118), ('વા', 326454)]\n"
          ]
        }
      ],
      "source": [
        "print(unigram_syllables_list_sorted_mbert_1000[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vxcRptVtkWB",
        "outputId": "81138f6a-9e72-4b4c-9474-3fcda2c20370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ ને', 156298), ('પ ર', 99945), ('મા ટે', 83902), ('એ ક', 76282), ('ક ર', 67544), ('વા મા', 55350), ('ર વા', 55337), ('પ ણ', 53867), ('ક રી', 50986), ('તે મ', 47219), ('કા ર', 45828), ('સા થે', 45217), ('હ તી', 32761), ('ન થી', 30447), ('વા ર', 28982), ('આ વે', 28186), ('ર ણ', 24979), ('હ તા', 23380), ('હો ય', 22624), ('હ તો', 21947)]\n"
          ]
        }
      ],
      "source": [
        "bigram_syllables_list_mbert_1000=[]\n",
        "bigram_syllables_list_sorted_mbert_1000=[]\n",
        "bigram_syllables_list_sorted_mbert_1000=get_bisyllable_frequency(unigram_syllabless,bigram_syllables_list_mbert_1000)\n",
        "print(bigram_syllables_list_sorted_mbert_1000[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeXOvO_YDB8v"
      },
      "source": [
        "# **mBERT max_length=2000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pnLtRJTFyD2"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, TFBertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased',max_length=2000,do_lower_case=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2ZL9_cJDWgZ",
        "outputId": "58c88e82-5853-4792-b56d-60d16890f74c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** mBert ***\n"
          ]
        }
      ],
      "source": [
        "print('*** mBert ***')\n",
        "with open('gu_100.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "# Tokenize a sentence\n",
        "\n",
        "# sentence = \"તમારું નામ શું છે?\"\n",
        "mbert_tokens2 = tokenizer.tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdJvUX17Dht8",
        "outputId": "92aae29d-3c8f-4a15-c826-674ffa50dc3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર', 726633), ('સ', 704144), ('મ', 683027), ('ક', 649642), ('પ', 624156), ('ા', 597880), ('ો', 580944), ('ે', 498472), ('િ', 455953), ('વ', 442840), ('ન', 440317), ('જ', 423183), ('લ', 383647), ('ી', 333884), ('ત', 333560), ('બ', 322287), ('છે', 321025), ('દ', 307605), ('્', 294539), ('હ', 286944)]\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "mBert_tokens_cleaned2 = [token.replace('#', '') for token in mbert_tokens2 if token not in punctuation_list ]\n",
        "\n",
        "# Count the frequency of each token\n",
        "mBert_token_freq2 = Counter(mBert_tokens_cleaned2)\n",
        "\n",
        "mBert_token_freq_list2 = list(mBert_token_freq2.items())\n",
        "# print(token_freq_list)\n",
        "mBert_sorted_token_freq_list2 = sorted(mBert_token_freq_list2, key=lambda x: x[1], reverse=True)\n",
        "print(mBert_sorted_token_freq_list2[:20])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3A6rDliARE9"
      },
      "source": [
        "# biagram of **Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgaufIE8ANCW",
        "outputId": "1cffe77f-4bcb-416b-c775-a26a3520e7b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('પ ્ર', 109266), ('વ િ', 95872), ('મ ે', 87313), ('ત મ', 68866), ('ર ્', 54493), ('સ ં', 51370), ('સ મ', 50033), ('સ ્', 49783), ('પ ો', 49127), ('ક ્', 47070), ('્ થ', 46468), ('ન િ', 44957), ('ક ર', 44654), ('જ ો', 44371), ('ર ા', 42642), ('મ ો', 42427), ('સ ર', 41479), ('પ ા', 41361), ('ા જ', 40165), ('મ ા', 38873)]\n"
          ]
        }
      ],
      "source": [
        "bigram_token_mbert_2000=[]\n",
        "bigram_token_mbert_2000_sorted=[]\n",
        "bigram_token_mbert_2000_sorted=get_bigramTokenizer_frequency(mBert_tokens_cleaned2)\n",
        "print(bigram_token_mbert_2000_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh8Fwip8twCn"
      },
      "source": [
        "# unigram and bigram of **character**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhXnHhU5t9T5"
      },
      "outputs": [],
      "source": [
        "processed_words_mbert_2000 = [] # list contain all the corrected unicode\n",
        "\n",
        "\n",
        "    # Process each word and store cleaned versions\n",
        "for word in mBert_tokens_cleaned2:\n",
        "  cleaned_word = correct_unicode(word)  # Explain what this function does\n",
        "  processed_words_mbert_2000.append(cleaned_word)\n",
        "        # print(f\"{word} => {cleaned_word}\")\n",
        "\n",
        "    # Increment the counter\n",
        "    # counter += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih10Pz_muN40",
        "outputId": "ffde11cd-99aa-49e5-dff2-0a6be6d874e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', ' મ્ ઈ', ' ઓ', ' ગ્ અ', ' સ્ ટ્ અ', '', '', '', '', ' ન્ આ']\n"
          ]
        }
      ],
      "source": [
        "N = 10\n",
        "result=[]\n",
        "result = processed_words_mbert_2000[:N]\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCTVM3AouQRa"
      },
      "source": [
        "**unigram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyh-LP2CuTYz"
      },
      "outputs": [],
      "source": [
        "unigram_char_list_mbert_2000=[]\n",
        "\n",
        "unigram_char_list_mbert_2000_sorted=[]\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "for word in processed_words_mbert_2000:\n",
        "\n",
        "  unigram_for_char(word, vyanjan,unigram_char_list_mbert_2000) # unigram for character\n",
        "\n",
        "  # print(\" unigram characters \")\n",
        "\n",
        "unigram_char_list_mbert_2000_sorted=sort_list_by_frequency(unigram_char_list_mbert_2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toXSAP8Uud-7",
        "outputId": "cde3e7ca-c8e0-4941-f425-d2cf2db80086"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ', 12713652), ('આ', 2357804), ('ર્', 2128340), ('એ', 1942445), ('ન્', 1733976), ('ક્', 1386470), ('મ્', 1324753), ('ઈ', 1255491), ('ત્', 1207677), ('વ્', 1149704), ('સ્', 976418), ('પ્', 867004), ('ય્', 745072), ('લ્', 684878), ('ઓ', 592856), ('જ્', 584943), ('ટ્', 520511), ('હ્', 516857), ('દ્', 427465), ('છ્', 412191)]\n"
          ]
        }
      ],
      "source": [
        "print(unigram_char_list_mbert_2000_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FblM5YSeuRyc"
      },
      "source": [
        "**bigram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpivjiT8ugFV",
        "outputId": "9120cec4-7b00-4026-9461-f915ba9800c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર્અ', 1609936), ('ક્અ', 1030111), ('મ્અ', 869185), ('સ્અ', 852688), ('પ્અ', 810258), ('ન્અ', 628773), ('વ્અ', 594341), ('ત્અ', 590295), ('જ્અ', 434663), ('લ્અ', 423574), ('મ્આ', 413067), ('ટ્અ', 400094), ('ય્અ', 398812), ('ગ્અ', 384654), ('હ્અ', 384602), ('અર', 367383), ('ન્એ', 361896), ('વ્આ', 345026), ('બ્અ', 337054), ('દ્અ', 325436)]\n"
          ]
        }
      ],
      "source": [
        "bigram_char_list_mbert_2000=[]\n",
        "\n",
        "bigram_char_list_mbert_2000_sorted=[]\n",
        "\n",
        "from collections import Counter\n",
        "for word in processed_words_mbert_2000:\n",
        "   bigram_for_char(word, vyanjan,bigram_char_list_mbert_2000) # bigram for character\n",
        "bigram_char_list_mbert_2000_sorted=sort_list_by_frequency(bigram_char_list_mbert_2000)\n",
        "print(bigram_char_list_mbert_2000_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0qyzI7Gt0FP"
      },
      "source": [
        "# unigram and bigram of **syllable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lSSGvdivqsp"
      },
      "outputs": [],
      "source": [
        "unigram_syllables_list_mbert_2000=[]\n",
        "unigram_syllabless=[]\n",
        "unigram_syllables_list_sorted_mbert_2000=[]\n",
        "swapped_dict = {v: k for k, v in gujarati_dict.items()}\n",
        "\n",
        "# print(swapped_dict)\n",
        "# resullt = [' મ્ ઈ', ' ઓ ગ્ અ સ્ ટ્ અ', ' ન્ આ']\n",
        "spchar = '@'\n",
        "count =0\n",
        "for word in processed_words_mbert_2000:\n",
        "\n",
        "  unigram_syllables(word,swar,vyanjan,swapped_dict,unigram_syllables_list_mbert_2000,unigram_syllabless)\n",
        "  unigram_syllabless.append(spchar)\n",
        "\n",
        "\n",
        "\n",
        "unigram_syllables_list_sorted_mbert_2000=sort_list_by_frequency(unigram_syllables_list_mbert_2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcWt6Cobv3fV",
        "outputId": "997ad4c8-e625-4eed-d944-1fb6ff42a7b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર', 1585387), ('ક', 1030111), ('મ', 869185), ('સ', 852688), ('પ', 810258), ('ન', 628773), ('વ', 588452), ('ત', 584201), ('જ', 434663), ('લ', 423574), ('મા', 413067), ('ગ', 384654), ('હ', 384602), ('ય', 370055), ('ને', 361896), ('અ', 354822), ('ટ', 346219), ('બ', 333300), ('આ', 331118), ('વા', 326454)]\n"
          ]
        }
      ],
      "source": [
        "print(unigram_syllables_list_sorted_mbert_2000[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrFOcNMFv8mF",
        "outputId": "2ca773d2-54da-47b3-ea66-7243bc517968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ ને', 156298), ('પ ર', 99945), ('મા ટે', 83902), ('એ ક', 76282), ('ક ર', 67544), ('વા મા', 55350), ('ર વા', 55337), ('પ ણ', 53867), ('ક રી', 50986), ('તે મ', 47219), ('કા ર', 45828), ('સા થે', 45217), ('હ તી', 32761), ('ન થી', 30447), ('વા ર', 28982), ('આ વે', 28186), ('ર ણ', 24979), ('હ તા', 23380), ('હો ય', 22624), ('હ તો', 21947)]\n"
          ]
        }
      ],
      "source": [
        "bigram_syllables_list_mbert_2000=[]\n",
        "bigram_syllables_list_sorted_mbert_2000=[]\n",
        "bigram_syllables_list_sorted_mbert_2000=get_bisyllable_frequency(unigram_syllabless,bigram_syllables_list_mbert_2000)\n",
        "print(bigram_syllables_list_sorted_mbert_2000[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY89ilRMFnEq"
      },
      "source": [
        "# **WhitespaceTokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaOGizkEFycc",
        "outputId": "7d6de165-15f9-4e80-94db-f642df2c8e89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** WhitespaceTokenizer ***\n",
            "[('છે.', 178482), ('અને', 151509), ('છે', 85214), ('આ', 78426), ('માટે', 74470), ('કે', 66147), ('એક', 58518), ('તે', 55611), ('પણ', 52790), ('પર', 46481), ('સાથે', 41610), ('છે,', 39966), ('કરી', 38986), ('જ', 37023), ('જે', 28405), ('તો', 27867), ('તમે', 25758), ('હતી.', 22541), ('કરવામાં', 20525), ('આવે', 20071)]\n",
            "['ડિસ્પ્લે', 'પર', 'પણ', 'યાંત્રિક', 'નુકસાન', 'કોર્નિંગ', 'ગ્લાસથી', 'એક', 'ખાસ', 'રક્ષણાત્મક', 'સ્તર', 'છે.', '(2017):', 'ઇ', '1270.', 'પાકિસ્તાનના', 'પીએમ', 'ઈમરાન', 'ખાનની', 'અધ્યક્ષતામાં', 'આ', 'બેઠક', 'બોલાવવામાં', 'આવી', 'છે.', 'આવી', 'ઘટનામાં', 'છેતરપિંડી', 'કરનાર', 'વ્યક્તિ', 'મોટે', 'ભાગે', 'પરિચિત', 'અથવા', 'તો', 'સંબંધી', 'હોય', 'છે', 'એ', 'વાત', 'વધારે', 'આઘાતજનક', 'હોય', 'છે.', 'આ', 'પતાવટની', 'આંતરમાળખા', 'ખૂબ', 'સારી', 'રીતે', 'વિકસિત', 'નથી.', 'આ', 'રકમ', 'આશરે', 'છે.', 'અમે', 'આ', 'મામલે', 'બહારનાં', 'વ્યક્તિનાં', 'કોઇ', 'પણ', 'દાવાને', 'સંપૂર્ણ', 'રીતે', 'ફગાવીએ', 'છીએ.', 'આ', 'કિસ્સાઓમાં', 'એન્ટિબાયોટિક્સ', 'સાથે', 'સારવાર', 'જરૂર', 'છે.', 'તમારી', 'રાશિના', 'લોકોએ', 'હાલ', 'દુર્ઘટનાઓથી', 'સાવધાન', 'રહેવાની', 'જરૂર', 'છે.', 'આ', 'બાબત', 'છે.', 'ત્યારબાદ', 'સીબીઆઇ', 'અને', 'ઇડીએ', 'પૂરક', 'ચાર્જશીટ', 'દાખલ', 'કરી', 'હતી', 'ઈન્ડિયન', 'આઈડલ', '11ના', 'આગામી', 'એપિસોડમાં', 'ઉદિત', 'નારાયણ', 'અને', 'અલકા', 'યાજ્ઞિક', 'મહેમાન', 'બનશે.', 'જ્યારે', 'ક્લેરિસ', 'અને', 'મિત્સુઇનો', 'સમાન', 'હિસ્સો', 'હતો.', 'આથી', 'ઋષિકેશ', 'નગરમાં', 'વિરભદ્ર', 'બંધના', 'દ્વાર', 'પાસે', 'તે', 'ફસાઈ', 'ગયો', 'હતો.', 'ઉરી', 'હુમલા', 'પછી', 'ભારતીય', 'સેના', 'તરફથી', 'સર્જિકલ', 'સ્ટ્રાઇક', 'કરવામાં', 'આવી.', 'આ', 'ખૂબ', 'જ', 'ખતરનાક', 'મિશનને', 'સફળતા', 'પૂર્વક', 'પાર', 'પાડવાનો', 'શ્રેય', 'જાય', 'છે', 'ભારતના', 'રાષ્ટ્રીય', 'સુરક્ષા', 'સલાહકાર', 'અજીત', 'ડોવાલ.', 'વ્યાપક', 'દરિયાકિનારો.', 'જેના', 'માટે', 'સરકારે', 'ઘણી', 'બધી', 'યોજનાઓ', 'પણ', 'ઘડી', 'છે', 'કે', 'ખેડૂતોને', 'થોડા', 'ઘણા', 'અંશે', 'પોતાની', 'તકલીફમાં', 'રાહત', 'મળી', 'રહે.', 'સ્પેન્સ', 'રીસ', 'શિષ્યવૃત્તિ.', 'જો', 'તમે', 'સલ્ફરમાંથી', 'સામયિક', 'ટેબલને', 'નીચે', 'ખસેડો.', 'તેમણે', 'કરોડોપતિનો', 'દરજ્જો', 'પ્રાપ્ત', 'કર્યો', 'છે', 'કારણ', 'કે', 'તેઓએ', 'સતત', 'ઘણી', 'સંપત્તિ', 'નિર્માણની', 'વ્યૂહરચનાઓનો', 'ઉપયોગ', 'કર્યો', 'છે', 'કે', 'જેમાંથી', 'કોઈ', 'પણ', 'ઉપયોગ', 'કરી', 'શકે', 'છે-', 'આજેથી', 'શરૂ', 'અહીં', 'આગામી', 'બારોમાંથી', 'મિલિયનેરના', 'બાર', 'લક્ષણો', 'છે:', 'પટ', 'પટતી', 'પાપણો', 'લોકો', 'કાદવ', 'માં', 'ન', 'હોઈ', 'શકે.', 'આ', 'લેખમાં', 'અમે', 'તમને', 'કહીશું', 'કે', 'સ્વિમિંગને', 'વધુ', 'રસપ્રદ.', 'વધુ', 'ખાસ', 'બાંધકામ', 'મિશ્રણ', 'વાપરીને', 'માળ', 'ભરવા', 'એક', 'મોટી', 'સોદો', 'નથી.', 'માર્કેટ', 'વેલ્યુની', 'દ્રષ્ટિએ', 'કોટક', 'મહિન્દ્રા', 'બેંક', 'એચડીએફસી', 'બાદ', 'બીજા', 'નંબરની.', 'SBIએ', 'એફડીના', 'વ્યાજ', 'દરમાં', '0.25', 'ટકા', 'સુધીનો.']\n"
          ]
        }
      ],
      "source": [
        "# import WhitespaceTokenizer() method from nltk\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "\n",
        "# Create a reference variable for Class WhitespaceTokenizer\n",
        "tk = WhitespaceTokenizer()\n",
        "\n",
        "# # Create a string input\n",
        "# gfg = \" લોકો બેંકોની બહાર ઊભાં રહી ગયાં હતાં\"\n",
        "\n",
        "# # Use tokenize method\n",
        "# geek = tk.tokenize(gfg)\n",
        "\n",
        "# print(geek)\n",
        "print('*** WhitespaceTokenizer ***')\n",
        "# sentence = \"લોકો બેંકોની બહાર ઊભાં રહી ગયાં હતાં\"\n",
        "# tokenized_input = tokenizer(sentence)\n",
        "\n",
        "\n",
        "\n",
        "with open('gu_100.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "# Tokenize a sentence\n",
        "with open('ques_25.txt', 'r', encoding='utf-8') as file:\n",
        "    text2 = file.read()\n",
        "whitespace_list = tk.tokenize(text)\n",
        "whitespace_list_ques_25 = tk.tokenize(text2)\n",
        "\n",
        "# print(\"segmented input sentence \",tokenizer.convert_ids_to_tokens(tokens['input_ids']))\n",
        "\n",
        "whitespace_tokens_cleaned = [token.replace('▁', '') for token in whitespace_list if token not in punctuation_list and token not in matra ]\n",
        "whitespace_tokens_cleaned_ques_25 = [token.replace('▁', '') for token in whitespace_list_ques_25 if token not in punctuation_list and token not in matra ]\n",
        "\n",
        "# Count the frequency of each token\n",
        "whitespace_token_freq = Counter(whitespace_tokens_cleaned)\n",
        "\n",
        "whitespace_token_freq_list = list(whitespace_token_freq.items())\n",
        "# print(token_freq_list)\n",
        "whitespace_sorted_token_freq_list = sorted(whitespace_token_freq_list, key=lambda x: x[1], reverse=True)\n",
        "print(whitespace_sorted_token_freq_list[:20])\n",
        "print(whitespace_tokens_cleaned_ques_25)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URAcNEIKAfFt"
      },
      "source": [
        "# biagram of **Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t210M34DAVoM",
        "outputId": "bb6b31a8-e832-4de0-c730-382a61c6109c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('છે કે', 20421), ('છે અને', 14265), ('છે. આ', 12280), ('શકે છે.', 9572), ('આવે છે.', 9429), ('કરવા માટે', 9424), ('કરે છે.', 8519), ('થાય છે.', 6206), ('કારણ કે', 5668), ('હોય છે.', 5559), ('કરવામાં આવે', 5311), ('કરવામાં આવી', 4972), ('શકો છો.', 4893), ('કેવી રીતે', 4881), ('કરી શકો', 4599), ('છે, અને', 4479), ('રહી છે.', 4236), ('આવે છે', 4213), ('છે જે', 4182), ('કરે છે', 4140)]\n"
          ]
        }
      ],
      "source": [
        "bigram_token_whitespace=[]\n",
        "bigram_token_whitespace_sorted=[]\n",
        "bigram_token_whitespace_sorted=get_bigramTokenizer_frequency(whitespace_tokens_cleaned)\n",
        "print(bigram_token_whitespace_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRUdMHc5xjzz"
      },
      "source": [
        "# unigram and bigram of **character**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gepkdh6NwO28",
        "outputId": "2549fae0-2237-4978-86d6-d2d6a3d16367"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[' મ્ ઈ', ' ઓ ગ્ અ સ્ ટ્ અ', ' ન્ આ', ' ર્ ઓ જ્ અ', ' આ દ્ ઇ વ્ આ સ્ ઈ', ' વ્ ઇ ક્ આ સ્ અ', ' સ્ અં ગ્ અ ઠ્ અ ન્ અ', ' દ્ વ્ આ ર્ આ', ' આ દ્ ઇ વ્ આ સ્ ઈ', ' ભ્ અ વ્ અ ન્ અ']\n"
          ]
        }
      ],
      "source": [
        "processed_words_whitespace = [] # list contain all the corrected unicode\n",
        "\n",
        "\n",
        "    # Process each word and store cleaned versions\n",
        "for word in whitespace_tokens_cleaned:\n",
        "  cleaned_word = correct_unicode(word)  # Explain what this function does\n",
        "  processed_words_whitespace.append(cleaned_word)\n",
        "        # print(f\"{word} => {cleaned_word}\")\n",
        "\n",
        "    # Increment the counter\n",
        "    # counter += 1\n",
        "N = 10\n",
        "result=[]\n",
        "result = processed_words_whitespace[:N]\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zdwaeZVwp7h"
      },
      "source": [
        "**unigram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr_oSZx8wvjz",
        "outputId": "642fe7a1-f700-4b04-a3eb-908a6747c2d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ', 6990268), ('આ', 3692279), ('એ', 2522856), ('ર્', 2128526), ('ન્', 1734112), ('ઈ', 1589073), ('ક્', 1386555), ('મ્', 1324843), ('ઓ', 1236360), ('ત્', 1207724), ('વ્', 1149790), ('સ્', 976491), ('પ્', 867048), ('ઇ', 838885), ('ય્', 745130), ('લ્', 684911), ('ઉ', 673954), ('જ્', 585042), ('ટ્', 520557), ('હ્', 516880)]\n"
          ]
        }
      ],
      "source": [
        "unigram_char_list_whitespace=[]\n",
        "\n",
        "unigram_char_list_whitespace_sorted=[]\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "for word in processed_words_whitespace:\n",
        "\n",
        "  unigram_for_char(word, vyanjan,unigram_char_list_whitespace) # unigram for character\n",
        "\n",
        "  # print(\" unigram characters \")\n",
        "\n",
        "unigram_char_list_whitespace_sorted=sort_list_by_frequency(unigram_char_list_whitespace)\n",
        "print(unigram_char_list_whitespace_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZriOsvUtwrd8"
      },
      "source": [
        "**bigram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux1UIdjTw6OV",
        "outputId": "1b0b3e3f-412d-4cfc-b6a2-9a00f81c40f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર્અ', 933782), ('અર', 856288), ('અન', 740690), ('ક્અ', 628714), ('મ્આ', 578634), ('આર', 436837), ('પ્અ', 419131), ('મ્અ', 410518), ('અમ', 405502), ('સ્અ', 404345), ('વ્આ', 403416), ('ન્અ', 383007), ('ન્એ', 374190), ('અત', 357387), ('અવ', 352507), ('ત્અ', 347304), ('ન્આ', 338880), ('છ્એ', 322605), ('વ્અ', 322164), ('ય્અ', 280834)]\n"
          ]
        }
      ],
      "source": [
        "bigram_char_list_whitespace=[]\n",
        "\n",
        "bigram_char_list_whitespace_sorted=[]\n",
        "\n",
        "from collections import Counter\n",
        "for word in processed_words_whitespace:\n",
        "   bigram_for_char(word, vyanjan,bigram_char_list_whitespace) # bigram for character\n",
        "bigram_char_list_whitespace_sorted=sort_list_by_frequency(bigram_char_list_whitespace)\n",
        "print(bigram_char_list_whitespace_sorted[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXcM4um3xAOH"
      },
      "source": [
        "# unigram and bigram of **syllable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAmpXh1JxERb",
        "outputId": "f05b2482-d314-430d-9414-6fbb01bfac3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ર', 769936), ('ક', 604335), ('મા', 567925), ('પ', 392100), ('મ', 383918), ('વા', 370332), ('ન', 369827), ('ને', 366840), ('અ', 353767), ('સ', 349703), ('ના', 334899), ('આ', 330561), ('છે', 322018), ('ત', 306720), ('વ', 286878), ('એ', 250054), ('ની', 240032), ('જ', 222568), ('લ', 215566), ('તે', 213475)]\n"
          ]
        }
      ],
      "source": [
        "unigram_syllables_list_whitespace=[]\n",
        "unigram_syllabless=[]\n",
        "unigram_syllables_list_sorted_whitespace=[]\n",
        "swapped_dict = {v: k for k, v in gujarati_dict.items()}\n",
        "\n",
        "# print(swapped_dict)\n",
        "# resullt = [' મ્ ઈ', ' ઓ ગ્ અ સ્ ટ્ અ', ' ન્ આ']\n",
        "spchar = '@'\n",
        "count =0\n",
        "for word in processed_words_whitespace:\n",
        "\n",
        "  unigram_syllables(word,swar,vyanjan,swapped_dict,unigram_syllables_list_whitespace,unigram_syllabless)\n",
        "  unigram_syllabless.append(spchar)\n",
        "\n",
        "\n",
        "\n",
        "unigram_syllables_list_sorted_whitespace=sort_list_by_frequency(unigram_syllables_list_whitespace)\n",
        "print(unigram_syllables_list_sorted_whitespace[:20])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P07jCt6jxVzH",
        "outputId": "097e3a3a-7dd2-4279-ecc3-7dfd0d319c2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('અ ને', 156342), ('ક ર', 95414), ('પ ર', 84047), ('મા ટે', 83961), ('ર વા', 69732), ('એ ક', 68081), ('પ ણ', 58282), ('ક રી', 56269), ('વા મા', 55647), ('સા થે', 45581), ('તે મ', 42669), ('ત મા', 40013), ('કા ર', 38255), ('સ મ', 33365), ('હ તી', 32939), ('ન થી', 32320), ('ઉ પ', 29503), ('આ વે', 28206), ('ત મે', 26162), ('વ વા', 24444)]\n"
          ]
        }
      ],
      "source": [
        "bigram_syllables_list_whitespace=[]\n",
        "bigram_syllables_list_sorted_whitespace=[]\n",
        "bigram_syllables_list_sorted_whitespace=get_bisyllable_frequency(unigram_syllabless,bigram_syllables_list_whitespace)\n",
        "print(bigram_syllables_list_sorted_whitespace[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i-chccxNHXG"
      },
      "source": [
        "# **Q5  find the precision, recall and F-score for the 25 sentences.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gWWlgUGNyzo",
        "outputId": "3ce2904e-030c-4580-9aed-bac65e535f38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision Recall F-Score of BPE\n",
            "Precision: 0.030254777070063694\n",
            "Recall: 0.17757009345794392\n",
            "F-score: 0.05170068027210885\n",
            " \n",
            "Precision Recall F-Score of Unigram\n",
            "Precision: 0.11023622047244094\n",
            "Recall: 0.3925233644859813\n",
            "F-score: 0.1721311475409836\n",
            " \n",
            "Precision Recall F-Score of mBert\n",
            "Precision: 0.011933174224343675\n",
            "Recall: 0.09345794392523364\n",
            "F-score: 0.021164021164021166\n",
            " \n",
            "Precision Recall F-Score of IndicBert\n",
            " \n",
            "Precision Recall F-Score of Whitespace Tokenizer\n",
            "Precision: 0.26037735849056604\n",
            "Recall: 0.6448598130841121\n",
            "F-score: 0.3709677419354839\n"
          ]
        }
      ],
      "source": [
        "# ques_25_cleaned_bpe\n",
        "# ques_25_cleaned_unigram\n",
        "# mbert_ques_25_tokens_cleaned\n",
        "# whitespace_tokens_cleaned_ques_25\n",
        "\n",
        "def calculate_metrics(ground_truth, predicted):\n",
        "    true_positives = len(set(ground_truth) & set(predicted))\n",
        "    precision = true_positives / len(predicted) if len(predicted) > 0 else 0\n",
        "    recall = true_positives / len(ground_truth) if len(ground_truth) > 0 else 0\n",
        "    f_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F-score:\", f_score)\n",
        "\n",
        "\n",
        "# Example lists\n",
        "\n",
        "ground_truth_labels = ['ગ્લાસથી', 'એક', 'રક્ષણાત્મક સ્તર', 'છે', 'યાંત્રિક નુકસાન', 'કોર્નિંગ', 'આ', 'પાકિસ્તાનના', 'ઈમરાન ખાનની', 'બોલાવવામાં', 'આવી છે', 'પીએમ', 'છેતરપિંડી', 'હોય છે', 'આઘાતજનક', 'આ', 'સારી', 'વિકસિત', 'પતાવટની', 'ખૂબ', 'આંતરમાળખા', 'આ', 'છે', 'આશરે', 'ફગાવીએ', 'સંપૂર્ણ', 'દાવાને', 'વ્યક્તિનાં', 'અમે', 'આ', 'મામલે', 'છીએ', 'આ', 'કિસ્સાઓમાં', 'જરૂર', 'છે', 'એન્ટિબાયોટિક્સ', 'તમારી', 'રાશિના', 'લોકોએ', 'દુર્ઘટનાઓથી', 'રહેવાની', 'જરૂર', 'હાલ', 'છે', 'આ', 'છે', 'બાબત', 'ઇડીએ', 'પૂરક', 'હતી', 'ચાર્જશીટ', 'ઈન્ડિયન આઈડલ 11ના', 'એપિસોડમાં', 'મહેમાન', 'બનશે', 'મિત્સુઇનો', 'હતો', 'બંધના', 'નગરમાં', 'હતો', 'મિશનને', 'ખતરનાક', 'પાડવાનો', 'ભારતના', 'સફળતા', 'આવી', 'વ્યાપક', 'દરિયાકિનારો', 'સરકારે', 'તકલીફમાં', 'ખેડૂતોને', 'થોડા ઘણા', 'અંશે પોતાની તકલીફમાં', 'યોજનાઓ', 'રહે', 'શિષ્યવૃત્તિ', 'સલ્ફરમાંથી', 'સામયિક ટેબલને', 'પ્રાપ્ત કર્યો', 'નિર્માણની', 'વ્યૂહરચનાઓનો', 'આજેથી', 'તેમણે', 'બારોમાંથી મિલિયનેરના', 'છે', 'મિલિયનેર', 'પાપણો', 'લોકો', 'શકે', 'લેખમાં', 'અમે', 'તમને', 'કહીશું', 'સ્વિમિંગને', 'વધુ', 'રસપ્રદ', 'વાપરીને', 'એક', 'ખાસ', 'મોટી મિશ્રણ વેલ્યુની', 'બીજા નંબરની', 'એફડીના', 'સુધીનો', 'એચડીએફસી', 'SBI', 'એફડી']\n",
        "# predicted=['ડિ', 'સ્', 'પ્', 'લે', 'પર', 'પણ', 'યા', 'ંત્ર', 'િક', 'ન', 'ુક', 'સ', 'ાન', 'કો', 'ર્', 'ન', 'િંગ', 'ગ', '્', 'લા', 'સ', 'થી', 'એક', 'ખાસ', 'ર', 'ક્ષ', 'ણા', 'ત્', 'મક', 'સ્', 'તર', 'છે', '4', '(', 'ઇ', '1', 'પા', 'કિ', 'સ્તા', 'નના', 'પી', 'એ', 'મ', 'ઈ', 'મ', 'રા', 'ન', 'ખ', 'ાન', 'ની', 'અધ', '્ય', 'ક્ષ', 'તા', 'માં', 'આ', 'બેઠ', 'ક', 'બો', 'લા', 'વ', 'વામાં', 'આવી', 'છે', 'આવી', 'ઘટના', 'માં', 'છે', 'તર', 'પ', 'િ', 'ં', 'ડી', 'કર', 'નાર', 'વ્યક્તિ', 'મો', 'ટે', 'ભા', 'ગે', 'પરિ', 'ચ', 'િત', 'અથવા', 'તો', 'સંબંધ', 'ી', 'હોય', 'છે', 'એ', 'વાત', 'વધ', 'ારે', 'આ', 'ઘ', 'ા', 'ત', 'જન', 'ક', 'હોય', 'છે', 'આ', 'પ', 'તા', 'વ', 'ટ', 'ની', 'આ', 'ંત', 'ર', 'મા', 'ળ', 'ખા', 'ખૂબ', 'સારી', 'રીતે', 'વિક', 'સ', 'િત', 'નથી', 'આ', 'ર', 'ક', 'મ', 'આ', 'શ', 'રે', 'છે', 'અમે', 'આ', 'મા', 'મ', 'લે', 'બહાર', 'નાં', 'વ્યક્તિ', 'નાં', 'કોઇ', 'પણ', 'દા', 'વા', 'ને', 'સંપૂર્ણ', 'રીતે', 'ફ', 'ગા', 'વી', 'એ', 'છ', 'ીએ', '', '-', 'આ', 'કિ', 'સ્', 'સા', 'ઓમાં', 'એ', 'ન્ટ', 'િ', 'બ', 'ાયો', 'ટ', 'િ', 'ક્સ', 'સાથે', 'સાર', 'વાર', 'જરૂર', 'છે', 'તમારી', 'રા', 'શિ', 'ના', 'લોકો', 'એ', 'હા', 'લ', 'દુ', 'ર્', 'ઘ', 'ટના', 'ઓ', 'થી', 'સા', 'વ', 'ધાન', 'રહે', 'વાની', 'જરૂર', 'છે', 'આ', 'બા', 'બ', 'ત', 'છે', 'ત', '્ય', 'ાર', 'બા', 'દ', 'સી', 'બી', 'આ', 'ઇ', 'અને', 'ઇ', 'ડી', 'એ', 'પ', 'ૂર', 'ક', 'ચ', 'ાર્', 'જ', 'શી', 'ટ', 'દા', 'ખ', 'લ', 'કરી', 'હતી', '.', 'ઈ', 'ન્ડ', 'િયન', 'આ', 'ઈ', 'ડ', 'લ', '1', 'ના', 'આગ', 'ામી', 'એ', 'પ', 'િ', 'સો', 'ડ', 'માં', 'ઉ', 'દ', 'િત', 'ના', 'રા', 'ય', 'ણ', 'અને', 'અલ', 'કા', 'યા', 'જ્', 'ઞ', 'િક', 'મ', 'હે', 'માન', 'બન', 'શે', 'જ્યારે', 'ક્', 'લે', 'ર', 'િસ', 'અને', 'મ', 'િત', '્સ', 'ુ', 'ઇ', 'નો', 'સ', 'માન', 'હિ', 'સ્', 'સો', 'હતો', 'આ', 'થી', '', 'ઋ', 'ષ', 'િક', 'ેશ', 'ન', 'ગ', 'રમાં', 'વિ', 'ર', 'ભ', 'દ', '્ર', 'બંધ', 'ના', 'દ્વા', 'ર', 'પાસે', 'તે', 'ફ', 'સા', 'ઈ', 'ગ', 'યો', 'હતો', 'ઉ', 'રી', 'હ', 'ુ', 'મ', 'લા', 'પછી', 'ભાર', 'તીય', 'સે', 'ના', 'તરફ', 'થી', 'સર્', 'જ', 'િક', 'લ', 'સ્ટ', '્રા', 'ઇ', 'ક', 'કરવામાં', 'આવી', 'આ', 'ખૂબ', 'જ', 'ખ', 'તર', 'ના', 'ક', 'મિ', 'શન', 'ને', 'સફ', 'ળ', 'તા', 'પૂર્', 'વ', 'ક', 'પ', 'ાર', 'પા', 'ડ', 'વાનો', 'શ્રે', 'ય', 'જાય', 'છે', 'ભારત', 'ના', 'રા', 'ષ્ટ', '્રી', 'ય', 'સુ', 'ર', 'ક્ષા', 'સ', 'લા', 'હ', 'કાર', 'અ', 'જી', 'ત', 'ડો', 'વા', 'લ', 'વ્યા', 'પ', 'ક', 'દર', 'િયા', 'કિ', 'ના', 'રો', 'જે', 'ના', 'માટે', 'સર', 'ક', 'ારે', 'ઘણી', 'બ', 'ધી', 'યો', 'જના', 'ઓ', 'પણ', 'ઘ', 'ડી', 'છે', 'કે', 'ખે', 'ડ', 'ૂ', 'તો', 'ને', 'થો', 'ડા', 'ઘણા', 'અ', 'ં', 'શે', 'પોતાની', 'ત', 'ક', 'લી', 'ફ', 'માં', 'રા', 'હ', 'ત', 'મળી', 'રહે', 'સ્', 'પે', 'ન્સ', 'રી', 'સ', 'શિ', 'ષ', '્ય', 'વ', 'ૃ', 'ત્', 'તિ', 'જો', 'તમે', 'સ', 'લ્', 'ફ', 'રમાં', 'થી', 'સામ', 'ય', 'િક', 'ટે', 'બ', 'લ', 'ને', 'ની', 'ચે', 'ખ', 'સે', 'ડો', 'તેમણે', 'કરો', 'ડો', 'પ', 'તિ', 'નો', 'દર', 'જ્', 'જો', 'પ્રા', 'પ્ત', 'કર્યો', 'છે', 'કારણ', 'કે', 'તેઓ', 'એ', 'સ', 'ત', 'ત', 'ઘણી', 'સં', 'પ', 'ત્', 'તિ', 'નિર્', 'મા', 'ણ', 'ની', 'વ્ય', 'ૂ', 'હ', 'ર', 'ચના', 'ઓ', 'નો', 'ઉપયોગ', 'કર્યો', 'છે', 'કે', 'જે', 'માંથી', 'કોઈ', 'પણ', 'ઉપયોગ', 'કરી', 'શકે', 'છે', 'આજે', 'થી', 'શરૂ', 'અહીં', 'આગ', 'ામી', 'બ', 'ારો', 'માંથી', 'મ', 'િલ', 'િય', 'ને', 'રના', 'બ', 'ાર', 'લ', 'ક્ષ', 'ણો', 'છે', 'પ', 'ટ', 'પ', 'ટ', 'તી', 'પા', 'પ', 'ણો', ':', 'લોકો', 'કા', 'દ', 'વ', 'માં', 'ન', 'હો', 'ઈ', 'શકે', 'આ', 'લે', 'ખ', 'માં', 'અમે', 'તમને', 'ક', 'હી', 'શ', 'ું', 'કે', 'સ્', 'વિ', 'મ', 'િંગ', 'ને', 'વધુ', 'ર', 'સ', 'પ્ર', 'દ', 'વધુ', 'ખાસ', 'બા', 'ંધ', 'કા', 'મ', 'મિ', 'શ', '્રણ', 'વા', 'પ', 'રી', 'ને', 'મા', 'ળ', 'ભ', 'ર', 'વા', 'એક', 'મો', 'ટી', 'સો', 'દો', 'નથી', 'માર્', 'કે', 'ટ', 'વે', 'લ', '્યુ', 'ની', 'દ', '્ર', 'ષ્ટ', 'િ', 'એ', 'કો', 'ટ', 'ક', 'મહિ', 'ન્દ', '્રા', 'બે', 'ંક', 'એ', 'ચ', 'ડી', 'એ', 'ફ', 'સી', 'બાદ', 'બીજા', 'ન', 'ં', 'બર', 'ની', '.', '.', '', 'એ', 'એ', 'ફ', 'ડી', 'ના', 'વ્યા', 'જ', 'દ', 'રમાં', '', 'ટકા', 'સુધી', 'નો']\n",
        "print(\"Precision Recall F-Score of BPE\")\n",
        "calculate_metrics(ground_truth_labels, ques_25_cleaned_bpe)\n",
        "print(\" \")\n",
        "print(\"Precision Recall F-Score of Unigram\")\n",
        "\n",
        "calculate_metrics(ground_truth_labels, ques_25_cleaned_unigram)\n",
        "print(\" \")\n",
        "print(\"Precision Recall F-Score of mBert\")\n",
        "\n",
        "calculate_metrics(ground_truth_labels, mbert_ques_25_tokens_cleaned)\n",
        "print(\" \")\n",
        "print(\"Precision Recall F-Score of IndicBert\")\n",
        "\n",
        "calculate_metrics(ground_truth_labels, indicBert_q25_list_cleaned)\n",
        "print(\" \")\n",
        "print(\"Precision Recall F-Score of Whitespace Tokenizer\")\n",
        "\n",
        "calculate_metrics(ground_truth_labels, whitespace_tokens_cleaned_ques_25)\n",
        "\n",
        "\n",
        "# print(ground_truth_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q6 **comparison**"
      ],
      "metadata": {
        "id": "BdbLf11iGGHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When comparing different tokenizers such as IndicBERT, whitespace tokenizer, unigram tokenizer, BPE tokenizer, and mBERT, I noticed variations in accuracy. Tokenizers like IndicBERT and whitespace tokenizer, which do not split words into multiple tokens, tend to yield higher accuracy. On the other hand, tokenizers like BPE and mBERT, which split words into multiple tokens, result in lower accuracy.\n",
        "\n",
        "To address this, I cleaned the tokens to remove unnecessary symbols. For example, in BPE, tokens containing \"_\" and \" \" were cleaned, and in mBERT, \"#\" and some tokens representing only matras were removed. This cleaning step helped improve accuracy, especially with tokenizers that split words into multiple tokens."
      ],
      "metadata": {
        "id": "bzmy3zHOGIY7"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FjxhTy5riJRi",
        "b-J5mKz3iCBn",
        "8XKGAtm4wiK3",
        "5YA5GXsv-8z3",
        "aY7Q-uzdk5Ul",
        "JKOBQnsTlmT4",
        "IrqGb9vbFt1Q",
        "ZDnAx-P0_a7u",
        "OuItRgCTmxRg",
        "Cf7lHQgcozU-",
        "xWnmSzLkwU7A",
        "ej91xJXeyJki",
        "KFcIqzJcyKcM",
        "qxEjcHrmyNE0",
        "9rxCDZmNCrXR",
        "FEVlfvDqDs_v",
        "UeYDof2MD-v0",
        "y6j-Ej28Fd5m",
        "4t5V5S--1yCP",
        "iNkDQcICAA2N",
        "1L_gdVQVrxns",
        "ZdvCgGE4tBj8",
        "XeXOvO_YDB8v",
        "U3A6rDliARE9",
        "Yh8Fwip8twCn",
        "f0qyzI7Gt0FP",
        "MY89ilRMFnEq",
        "URAcNEIKAfFt",
        "NRUdMHc5xjzz",
        "fXcM4um3xAOH"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}